%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ch04_solutions.tex
% Answer Key for Chapter 4: Two-Electron Integrals and Rys Quadrature Foundations
%
% Course: 2302638 Advanced Quantum Chemistry
% Institution: Department of Chemistry, Faculty of Science, Chulalongkorn University
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{../../solutions_style}

\title{\textbf{Chapter 4: Answer Key}\\
\large Two-Electron Integrals and Rys Quadrature Foundations\\
\normalsize 2302638 Advanced Quantum Chemistry}
\author{Department of Chemistry, Chulalongkorn University}
\date{}

\begin{document}
\maketitle
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Overview}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This answer key covers:
\begin{itemize}
    \item \textbf{13 Checkpoint Questions} embedded throughout Chapter 4, testing conceptual understanding of ERIs and the Boys function
    \item \textbf{3 Python Labs} (4A, 4B, 4C) with expected numerical results and validation criteria
\end{itemize}

\noindent\textbf{Validation standard:} All numerical results should match PySCF reference calculations to within the specified tolerances.

\noindent\textbf{Key topics covered:}
\begin{itemize}
    \item ERI definition and 8-fold symmetry
    \item Schwarz screening and computational cost
    \item The $(ss|ss)$ primitive ERI formula
    \item Boys function properties, series expansion, and recursion relations
    \item Introduction to Rys quadrature concepts
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Checkpoint Question Answers}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This section provides detailed answers to all 13 checkpoint questions from Chapter 4,
organized by their location in the chapter.

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.1: Mental Model for ERIs}
\label{sec:cp41}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.1 -- ERI Definition]
\textbf{Question:} An ERI $\eri{\mu}{\nu}{\lambda}{\sigma}$ represents the Coulomb interaction between two
\emph{overlap distributions}: $\chi_\mu(\rvec)\chi_\nu(\rvec)$ on electron~1
and $\chi_\lambda(\rvec)\chi_\sigma(\rvec)$ on electron~2.
Why does a four-index quantity arise from a two-body operator?
What physical information is encoded in each pair of indices?

\textbf{Answer:}

\textbf{Why four indices arise from a two-body operator:}

The electron-electron repulsion operator $\hat{V}_{ee} = 1/r_{12}$ acts on \emph{two} electrons simultaneously. In the LCAO expansion, each electron's wavefunction is expanded in the basis $\{\chi_\mu\}$:
\begin{itemize}
    \item Electron 1: $\psi(\rvec_1) = \sum_\mu c_\mu \chi_\mu(\rvec_1)$ and $\psi'(\rvec_1) = \sum_\nu c'_\nu \chi_\nu(\rvec_1)$
    \item Electron 2: $\psi(\rvec_2) = \sum_\lambda c_\lambda \chi_\lambda(\rvec_2)$ and $\psi'(\rvec_2) = \sum_\sigma c'_\sigma \chi_\sigma(\rvec_2)$
\end{itemize}

The matrix element $\langle\psi\psi'|r_{12}^{-1}|\psi\psi'\rangle$ requires four basis function indices---two for each electron. This is fundamentally different from one-electron operators (like kinetic energy or nuclear attraction) which only need two indices.

\textbf{Physical information in each pair of indices:}

\begin{itemize}
    \item \textbf{Bra pair $(\mu,\nu)$:} Describes the \emph{overlap distribution} $\chi_\mu(\rvec)\chi_\nu(\rvec)$ for electron~1. This is a ``charge cloud'' representing where electron~1 is likely to be found when transitioning between orbitals $\mu$ and $\nu$. The distribution is centered between the centers of $\chi_\mu$ and $\chi_\nu$.

    \item \textbf{Ket pair $(\lambda,\sigma)$:} Describes the overlap distribution $\chi_\lambda(\rvec)\chi_\sigma(\rvec)$ for electron~2, similarly representing a charge cloud.
\end{itemize}

The ERI $\eri{\mu}{\nu}{\lambda}{\sigma}$ is the classical Coulomb repulsion energy between these two charge distributions:
\[
\eri{\mu}{\nu}{\lambda}{\sigma} = \iint \underbrace{\chi_\mu(\rvec_1)\chi_\nu(\rvec_1)}_{\text{charge cloud 1}} \frac{1}{r_{12}} \underbrace{\chi_\lambda(\rvec_2)\chi_\sigma(\rvec_2)}_{\text{charge cloud 2}} d\rvec_1 d\rvec_2
\]

\textbf{Special cases and their role in Fock matrix construction:}
\begin{itemize}
    \item $\eri{\mu}{\mu}{\lambda}{\lambda}$: Coulomb repulsion between diagonal charge densities $|\chi_\mu|^2$ and $|\chi_\lambda|^2$
    \item $\eri{\mu}{\nu}{\mu}{\nu}$ with $\mu \neq \nu$: Coulomb repulsion between the overlap distribution $\chi_\mu\chi_\nu$ on both electrons
\end{itemize}

\textbf{Important distinction---Coulomb vs.\ Exchange contributions:}
In the AO basis, \emph{all} ERIs represent classical Coulomb repulsions between charge clouds. The terms ``Coulomb integral'' and ``exchange integral'' properly refer to MO-basis quantities:
\begin{align*}
    J_{ij} &= (ii|jj) && \text{(Coulomb integral in MO basis)} \\
    K_{ij} &= (ij|ji) && \text{(Exchange integral in MO basis)}
\end{align*}
The ``exchange energy'' has no classical analog not because the integral $(ij|ji)$ itself is non-classical, but because exchange arises from wavefunction antisymmetry (Pauli principle). In the AO basis, the distinction emerges through \emph{contraction patterns}:
\begin{align*}
    J_{\mu\nu} &= \sum_{\lambda\sigma} \eri{\mu}{\nu}{\lambda}{\sigma} P_{\lambda\sigma} && \text{(bra indices fixed)} \\
    K_{\mu\nu} &= \sum_{\lambda\sigma} \eri{\mu}{\lambda}{\nu}{\sigma} P_{\lambda\sigma} && \text{(indices interleaved)}
\end{align*}
\end{checkpointAnswer}

\begin{physicalinsightbox}
The ``four-index'' nature of ERIs is the fundamental reason why electron-electron repulsion is computationally expensive: storing $N^4$ quantities and contracting them scales as $\bigO{N^4}$, compared to $\bigO{N^2}$ for one-electron integrals.
\end{physicalinsightbox}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.2: Notation Warning---Chemist's vs.\ Physicist's}
\label{sec:cp42}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.2 -- Notation Conventions]
\textbf{Question:} Physicist's notation uses different index ordering:
\[
\langle \mu\lambda | \nu\sigma \rangle_{\text{physicist}}
= \eri{\mu}{\nu}{\lambda}{\sigma}_{\text{chemist}}.
\]
In physicist's convention, the first and third indices form the bra; the second and fourth
form the ket. This course uses chemist's notation exclusively. Understand the difference.

\textbf{Answer:}

\textbf{Understanding the difference:}

\begin{center}
\begin{tabular}{lcc}
\toprule
& \textbf{Chemist's} & \textbf{Physicist's} \\
\midrule
Notation & $\eri{\mu}{\nu}{\lambda}{\sigma}$ & $\langle\mu\lambda|\nu\sigma\rangle$ \\
Electron 1 indices & $\mu, \nu$ (bra) & $\mu, \nu$ (1st, 2nd) \\
Electron 2 indices & $\lambda, \sigma$ (ket) & $\lambda, \sigma$ (3rd, 4th) \\
Index grouping & $(12|34)$ & $\langle 13|24\rangle$ \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Translation rule:}
\[
\langle \mu\lambda | \nu\sigma \rangle_{\text{physicist}} = \eri{\mu}{\nu}{\lambda}{\sigma}_{\text{chemist}}
\]
or equivalently:
\[
\eri{\mu}{\nu}{\lambda}{\sigma}_{\text{chemist}} = \langle \mu\lambda | \nu\sigma \rangle_{\text{physicist}}
\]

\textbf{Why chemist's notation is preferred in this course:}
\begin{enumerate}
    \item \textbf{Index locality:} Adjacent indices in $\eri{\mu}{\nu}{\lambda}{\sigma}$ refer to the same electron, making symmetry relations easier to see.
    \item \textbf{Computational relevance:} Most quantum chemistry codes (including PySCF, Gaussian, Q-Chem) use chemist's notation internally.
    \item \textbf{Contraction patterns:} The J and K matrix contractions are more transparent:
    \begin{align*}
    J_{\mu\nu} &= \sum_{\lambda\sigma} \eri{\mu}{\nu}{\lambda}{\sigma} P_{\lambda\sigma} && \text{(adjacent indices paired)}\\
    K_{\mu\nu} &= \sum_{\lambda\sigma} \eri{\mu}{\lambda}{\nu}{\sigma} P_{\lambda\sigma} && \text{(alternating indices paired)}
    \end{align*}
\end{enumerate}

\textbf{Common pitfall:} When reading physics-oriented textbooks (e.g., Sakurai, Griffiths), ERIs often appear in physicist's notation. Always check the definition before implementing equations.
\end{checkpointAnswer}

\begin{warningbox}
A sign or factor error when mixing conventions can lead to completely wrong energies. The exchange energy has opposite signs in some formalisms. Always verify the convention being used.
\end{warningbox}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.3: 8-Fold Symmetry}
\label{sec:cp43}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.3 -- ERI Symmetries]
\textbf{Question:} Starting from the three fundamental symmetries:
\begin{align*}
\eri{\mu}{\nu}{\lambda}{\sigma} &= \eri{\nu}{\mu}{\lambda}{\sigma} && \text{(bra swap)} \\
\eri{\mu}{\nu}{\lambda}{\sigma} &= \eri{\mu}{\nu}{\sigma}{\lambda} && \text{(ket swap)} \\
\eri{\mu}{\nu}{\lambda}{\sigma} &= \eri{\lambda}{\sigma}{\mu}{\nu} && \text{(bra-ket exchange)}
\end{align*}
\begin{enumerate}[label=(\alph*)]
    \item List all 8 index orderings equivalent to $\eri{\mu}{\nu}{\lambda}{\sigma}$.
    \item For $N = 100$ basis functions, how many unique ERIs must be stored? Compare to the full $N^4 = 10^8$ tensor.
    \item Why does the bra-ket exchange have the clearest physical interpretation?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) All 8 equivalent index orderings:}

Starting from $\eri{\mu}{\nu}{\lambda}{\sigma}$, we can apply the three generators:
\begin{enumerate}
    \item $\eri{\mu}{\nu}{\lambda}{\sigma}$ (identity)
    \item $\eri{\nu}{\mu}{\lambda}{\sigma}$ (bra swap)
    \item $\eri{\mu}{\nu}{\sigma}{\lambda}$ (ket swap)
    \item $\eri{\nu}{\mu}{\sigma}{\lambda}$ (bra swap + ket swap)
    \item $\eri{\lambda}{\sigma}{\mu}{\nu}$ (bra-ket exchange)
    \item $\eri{\sigma}{\lambda}{\mu}{\nu}$ (bra-ket exchange + bra swap)
    \item $\eri{\lambda}{\sigma}{\nu}{\mu}$ (bra-ket exchange + ket swap)
    \item $\eri{\sigma}{\lambda}{\nu}{\mu}$ (bra-ket exchange + bra swap + ket swap)
\end{enumerate}

These 8 orderings form a group isomorphic to $\mathbb{Z}_2 \times \mathbb{Z}_2 \times \mathbb{Z}_2$.

\textbf{(b) Unique ERIs for $N = 100$:}

The exact formula for the number of unique ERIs is:
\[
N_{\text{unique}} = \frac{n_{12}(n_{12}+1)}{2}, \quad \text{where } n_{12} = \frac{N(N+1)}{2}
\]
This accounts for the triangular packing of pairs within each electron and between electrons.

For $N = 100$:
\[
n_{12} = \frac{100 \times 101}{2} = 5050
\]
\[
N_{\text{unique}} = \frac{5050 \times 5051}{2} = 12{,}753{,}775
\]

Comparison:
\begin{center}
\begin{tabular}{lrl}
\toprule
Storage & Count & Memory (8 bytes each) \\
\midrule
Full $N^4$ & $10^8$ & 800 MB \\
8-fold symmetric & $1.28 \times 10^7$ & 102 MB \\
\midrule
\textbf{Savings} & \multicolumn{2}{c}{\textbf{Factor of $\sim$7.8}} \\
\bottomrule
\end{tabular}
\end{center}

The factor is slightly less than 8 because diagonal cases (where some indices coincide) have fewer distinct permutations.

\textbf{(c) Physical interpretation of bra-ket exchange:}

The bra-ket exchange symmetry $\eri{\mu}{\nu}{\lambda}{\sigma} = \eri{\lambda}{\sigma}{\mu}{\nu}$ has the clearest physical meaning because it reflects the \textbf{fundamental indistinguishability of electrons}.

Physical reasoning:
\begin{itemize}
    \item The labels ``electron 1'' and ``electron 2'' are arbitrary---electrons have no identity.
    \item Swapping these labels should not change any observable quantity.
    \item The Coulomb interaction $1/r_{12} = 1/r_{21}$ is symmetric in the electron coordinates.
\end{itemize}

In contrast, the bra and ket swaps arise from the \emph{mathematical} property that real functions satisfy $\chi_\mu\chi_\nu = \chi_\nu\chi_\mu$---a statement about the commutativity of multiplication, not about physics.

The bra-ket exchange symmetry is the only one that survives for complex orbitals (with appropriate complex conjugation), while the bra/ket swaps become more complicated.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.4: Cost-Benefit of Screening}
\label{sec:cp44}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.4 -- Schwarz Screening]
\textbf{Question:} Schwarz screening requires computing $\bigO{N^2}$ diagonal integrals $\eri{\mu}{\nu}{\mu}{\nu}$
before screening begins.
\begin{enumerate}[label=(\alph*)]
    \item Why is this $\bigO{N^2}$ overhead worthwhile when the goal is to avoid $\bigO{N^4}$ work?
    \item If 90\% of ERIs are screened away, what is the effective scaling of the remaining work?
    \item For a very compact molecule (all atoms close together), would you expect more or fewer ERIs to survive screening compared to an extended molecule?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Why $\bigO{N^2}$ overhead is worthwhile:}

The Schwarz screening overhead is $\bigO{N^2}$ while the potential savings are from $\bigO{N^4}$. The ratio of work is:
\[
\frac{\text{Screening cost}}{\text{Full ERI cost}} \sim \frac{N^2}{N^4} = \frac{1}{N^2}
\]

For $N = 100$: overhead is $\sim 0.01\%$ of full cost.
For $N = 1000$: overhead is $\sim 0.0001\%$ of full cost.

Even if screening only eliminates a modest fraction of ERIs, the overhead is negligible for any reasonably sized system. The screening becomes increasingly worthwhile as $N$ grows.

\textbf{(b) Effective scaling when 90\% are screened:}

If 90\% of ERIs are screened, only 10\% survive. The work becomes:
\[
W_{\text{screened}} = 0.1 \times N^4 = 0.1 N^4
\]

This is still formally $\bigO{N^4}$---the \emph{asymptotic} scaling is unchanged. However, the prefactor is reduced by a factor of 10, which is significant in practice.

\textbf{Important:} The fraction screened typically \emph{increases} with system size for extended molecules, because distant basis pairs have exponentially small Schwarz bounds. In favorable cases (1D chains, surfaces), the number of significant ERIs can scale as $\bigO{N^2}$ or even $\bigO{N}$.

\textbf{(c) Compact vs.\ extended molecules:}

\textbf{Compact molecules} (all atoms within a few \AA):
\begin{itemize}
    \item All basis functions have significant spatial overlap
    \item Schwarz bounds $Q_{\mu\nu} = \sqrt{\eri{\mu}{\nu}{\mu}{\nu}}$ are mostly non-negligible
    \item Few ERIs are screened---most survive
    \item Effective scaling remains close to $\bigO{N^4}$
\end{itemize}

\textbf{Extended molecules} (linear chains, surfaces, large biomolecules):
\begin{itemize}
    \item Basis functions on distant atoms have negligible overlap
    \item Schwarz bounds decay exponentially: $Q_{\mu\nu} \sim e^{-\alpha R_{\mu\nu}^2}$
    \item Many ERIs are screened (often $>99\%$ for large systems)
    \item Effective scaling can approach $\bigO{N^2}$ or better
\end{itemize}

\textbf{Physical intuition:} Gaussian basis functions are localized. If two functions are separated by many times their ``width,'' their overlap is exponentially small. Extended molecules have many such distant pairs; compact molecules have few.
\end{checkpointAnswer}

\begin{keyformulabox}
Schwarz inequality: $|\eri{\mu}{\nu}{\lambda}{\sigma}| \le Q_{\mu\nu} \cdot Q_{\lambda\sigma}$ where $Q_{\mu\nu} = \sqrt{\eri{\mu}{\nu}{\mu}{\nu}}$.

If $Q_{\mu\nu} \cdot Q_{\lambda\sigma} < \tau$ (typically $\tau \sim 10^{-10}$), the ERI is skipped.
\end{keyformulabox}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.5: Structure of the $(ss|ss)$ Formula}
\label{sec:cp45}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.5 -- Primitive ERI Structure]
\textbf{Question:} Examine the $(ss|ss)$ ERI formula:
\[
(ab|cd) = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}\,e^{-\mu R_{AB}^2}\,e^{-\nu R_{CD}^2}\,\Boys{0}(T),
\quad T = \frac{pq}{p+q}|\mathbf{P}-\mathbf{Q}|^2
\]
and answer:
\begin{enumerate}[label=(\alph*), noitemsep]
    \item Which factors depend \emph{only} on the bra pair $(\mathbf{A},\mathbf{B},\alpha,\beta)$?
    \item Which factors depend \emph{only} on the ket pair $(\mathbf{C},\mathbf{D},\gamma,\delta)$?
    \item What role does $R_{PQ} = |\mathbf{P}-\mathbf{Q}|$ play? Why does this ``effective distance'' between pair centers control the ERI magnitude?
    \item If $\mathbf{A}=\mathbf{B}$ (same-center case), what happens to $R_{AB}$ and $\mu$? How does this affect the exponential prefactor?
    \item What happens when $R_{PQ} \to 0$ (pair centers coincide)? What is $\Boys{0}(0)$?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Bra-pair-only factors:}

The following depend only on the bra pair $(\mathbf{A},\mathbf{B},\alpha,\beta)$:
\begin{itemize}
    \item $p = \alpha + \beta$ (total exponent)
    \item $\mu = \frac{\alpha\beta}{\alpha+\beta}$ (reduced exponent)
    \item $\mathbf{P} = \frac{\alpha\mathbf{A}+\beta\mathbf{B}}{\alpha+\beta}$ (composite center)
    \item $R_{AB} = |\mathbf{A}-\mathbf{B}|$ (primitive separation)
    \item $e^{-\mu R_{AB}^2}$ (intra-pair decay factor)
\end{itemize}

\textbf{(b) Ket-pair-only factors:}

Similarly, these depend only on the ket pair $(\mathbf{C},\mathbf{D},\gamma,\delta)$:
\begin{itemize}
    \item $q = \gamma + \delta$ (total exponent)
    \item $\nu = \frac{\gamma\delta}{\gamma+\delta}$ (reduced exponent)
    \item $\mathbf{Q} = \frac{\gamma\mathbf{C}+\delta\mathbf{D}}{\gamma+\delta}$ (composite center)
    \item $R_{CD} = |\mathbf{C}-\mathbf{D}|$ (primitive separation)
    \item $e^{-\nu R_{CD}^2}$ (intra-pair decay factor)
\end{itemize}

\textbf{(c) Role of $R_{PQ}$ (inter-pair separation):}

The distance $R_{PQ} = |\mathbf{P}-\mathbf{Q}|$ appears in the Boys function argument:
\[
T = \rho R_{PQ}^2, \quad \text{where } \rho = \frac{pq}{p+q}
\]

\textbf{Physical interpretation:}
\begin{itemize}
    \item $\mathbf{P}$ is the ``center of charge'' for the electron-1 overlap distribution $\chi_a\chi_b$
    \item $\mathbf{Q}$ is the ``center of charge'' for the electron-2 overlap distribution $\chi_c\chi_d$
    \item $R_{PQ}$ measures how far apart these two charge clouds are
    \item The Boys function $\Boys{0}(T)$ encodes the Coulomb interaction decay with separation
\end{itemize}

As $R_{PQ}$ increases:
\begin{itemize}
    \item $T = \rho R_{PQ}^2$ grows
    \item $\Boys{0}(T) \to \frac{1}{2}\sqrt{\pi/T} \sim 1/R_{PQ}$ for large $T$
    \item The ERI decays as $\sim 1/R_{PQ}$ (the familiar Coulomb $1/r$ decay)
\end{itemize}

\textbf{(d) Same-center case ($\mathbf{A} = \mathbf{B}$):}

When $\mathbf{A} = \mathbf{B}$:
\begin{itemize}
    \item $R_{AB} = 0$
    \item The exponential becomes $e^{-\mu R_{AB}^2} = e^0 = 1$
    \item The composite center $\mathbf{P} = \frac{\alpha\mathbf{A}+\beta\mathbf{A}}{\alpha+\beta} = \mathbf{A}$
\end{itemize}

This is the ``diagonal'' case where both primitives are on the same atom. The intra-pair decay factor is absent, and the ERI depends only on the ket-pair geometry and the inter-pair separation.

\textbf{(e) Coinciding pair centers ($R_{PQ} \to 0$):}

When $\mathbf{P} = \mathbf{Q}$:
\begin{itemize}
    \item $R_{PQ} = 0$, so $T = \rho \cdot 0 = 0$
    \item $\Boys{0}(0) = 1$ (from the definition: $\int_0^1 1 \cdot e^0 \, dt = 1$)
\end{itemize}

The ERI reduces to:
\[
(ab|cd)\big|_{R_{PQ}=0} = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}\,e^{-\mu R_{AB}^2}\,e^{-\nu R_{CD}^2}
\]

This is finite and represents the maximum Coulomb repulsion when the two overlap distributions are centered at the same point.
\end{checkpointAnswer}

\begin{physicalinsightbox}
The $(ss|ss)$ formula cleanly separates:
\begin{enumerate}
    \item \textbf{Intra-pair factors} ($e^{-\mu R_{AB}^2}$, $e^{-\nu R_{CD}^2}$): Measure how ``spread out'' each overlap distribution is based on primitive separations.
    \item \textbf{Inter-pair factor} ($\Boys{0}(T)$): Measures the Coulomb repulsion between the two distributions based on their center-to-center separation.
\end{enumerate}
\end{physicalinsightbox}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.6: Boys Function Properties}
\label{sec:cp46}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.6 -- Boys Function]
\textbf{Question:}
\begin{enumerate}[label=(\alph*), noitemsep]
    \item Verify that $\Boys{n}(0) = 1/(2n+1)$ for $n = 0, 1, 2, 3$ by evaluating the integral directly.
    \item For $T = 1.0$, estimate $\Boys{0}(1)$ using the erf formula. (Hint: $\operatorname{erf}(1) \approx 0.8427$.)
    \item The derivative identity states $\frac{d}{dT}\Boys{n}(T) = -\Boys{n+1}(T)$. Why is this derivative always negative? What does it say about how $\Boys{n}(T)$ changes with $T$?
    \item At $T = 0.001$, estimate $(2 \cdot 0 + 1)\Boys{0}(T) - e^{-T}$. Why does upward recursion suffer from cancellation here?
    \item If your implementation returns negative values for large $n$, what is the likely bug?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Verify $\Boys{n}(0) = 1/(2n+1)$:}

At $T = 0$, the Boys function becomes:
\[
\Boys{n}(0) = \int_0^1 t^{2n} e^0 \, dt = \int_0^1 t^{2n} \, dt = \left[\frac{t^{2n+1}}{2n+1}\right]_0^1 = \frac{1}{2n+1}
\]

Explicit values:
\begin{center}
\begin{tabular}{ccc}
\toprule
$n$ & $\Boys{n}(0)$ & Decimal \\
\midrule
0 & $1/1 = 1$ & 1.0000 \\
1 & $1/3$ & 0.3333 \\
2 & $1/5$ & 0.2000 \\
3 & $1/7$ & 0.1429 \\
\bottomrule
\end{tabular}
\end{center}

\textbf{(b) Estimate $\Boys{0}(1)$ using the erf formula:}

The closed form is:
\[
\Boys{0}(T) = \frac{1}{2}\sqrt{\frac{\pi}{T}}\,\operatorname{erf}(\sqrt{T})
\]

At $T = 1$:
\[
\Boys{0}(1) = \frac{1}{2}\sqrt{\frac{\pi}{1}}\,\operatorname{erf}(1) = \frac{\sqrt{\pi}}{2} \times 0.8427 \approx \frac{1.7725}{2} \times 0.8427 \approx 0.7468
\]

(Exact value: $\Boys{0}(1) \approx 0.746824133$)

\textbf{(c) Why is $\frac{d}{dT}\Boys{n}(T) = -\Boys{n+1}(T)$ always negative?}

The derivative identity follows from differentiating under the integral:
\[
\frac{d}{dT}\Boys{n}(T) = \frac{d}{dT}\int_0^1 t^{2n} e^{-Tt^2} \, dt = \int_0^1 t^{2n} (-t^2) e^{-Tt^2} \, dt = -\int_0^1 t^{2n+2} e^{-Tt^2} \, dt = -\Boys{n+1}(T)
\]

Since $\Boys{n+1}(T) > 0$ for all $T \ge 0$ (the integrand is non-negative and not identically zero), we have:
\[
\frac{d}{dT}\Boys{n}(T) < 0 \quad \text{for all } T \ge 0
\]

\textbf{Physical meaning:} $\Boys{n}(T)$ is monotonically \emph{decreasing} in $T$. As $T$ increases (pair centers separate), the Boys function decreases, reflecting the decay of the Coulomb interaction.

\textbf{(d) Cancellation in upward recursion at small $T$:}

At $T = 0.001$, we compute the numerator of the upward recursion:
\[
(2n+1)\Boys{n}(T) - e^{-T}
\]

For $n = 0$:
\begin{align*}
\Boys{0}(0.001) &\approx \Boys{0}(0) - 0.001 \cdot \Boys{1}(0) + \ldots \approx 1 - \frac{0.001}{3} \approx 0.9997 \\
e^{-0.001} &\approx 1 - 0.001 + \frac{0.001^2}{2} \approx 0.999
\end{align*}

The numerator:
\[
1 \cdot 0.9997 - 0.999 \approx 0.0007
\]

We are subtracting two numbers that are both close to 1 to get a result of order $10^{-4}$. This loses approximately 3--4 significant digits.

For larger $n$, the cancellation worsens because $(2n+1)\Boys{n}(T)$ and $e^{-T}$ approach each other more closely.

\textbf{(e) Negative values for large $n$:}

If your Boys function returns negative values for large $n$, the likely bug is \textbf{using upward recursion at small $T$}.

The upward recursion:
\[
\Boys{n+1}(T) = \frac{(2n+1)\Boys{n}(T) - e^{-T}}{2T}
\]
suffers from catastrophic cancellation when $T$ is small. The numerator becomes a small difference of nearly equal numbers, and dividing by the small $2T$ amplifies rounding errors. After several iterations, errors accumulate and can produce negative (unphysical) values.

\textbf{Fix:} Use the series expansion for small $T$ (typically $T < 25$), which is numerically stable.
\end{checkpointAnswer}

\begin{keyformulabox}
Boys function recursions:
\begin{align*}
\text{Upward:} && \Boys{n+1}(T) &= \frac{(2n+1)\Boys{n}(T) - e^{-T}}{2T} && \text{(stable for large $T$)}\\
\text{Downward:} && \Boys{n}(T) &= \frac{2T\Boys{n+1}(T) + e^{-T}}{2n+1} && \text{(always stable)}\\
\text{Series:} && \Boys{n}(T) &= \sum_{k=0}^{\infty} \frac{(-T)^k}{k!(2n+2k+1)} && \text{(stable for small $T$)}
\end{align*}
\end{keyformulabox}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.7: Quadrature Comparison}
\label{sec:cp47}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.7 -- Numerical Quadrature]
\textbf{Question:}
\begin{enumerate}[label=(\alph*),noitemsep]
  \item The 2-point trapezoidal rule is exact for polynomials of degree at most 1.
        What degree does 2-point Gaussian quadrature achieve?
  \item Simpson's rule uses 3 equally spaced points and is exact for cubics (degree 3).
        How many Gaussian nodes would you need to match this?
  \item Why might Newton--Cotes rules still be preferred in some applications despite
        their lower accuracy per node?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Degree achieved by 2-point Gaussian quadrature:}

Two-point Gaussian quadrature achieves \textbf{degree 3}---it exactly integrates all polynomials up to degree 3.

An $n$-point Gaussian quadrature rule has $2n$ free parameters ($n$ nodes + $n$ weights). With $n = 2$ points, we have 4 parameters. Requiring the rule to exactly integrate monomials $1, x, x^2, x^3$ gives 4 equations (the moment conditions):
\begin{align*}
\sum_i W_i &= \int_a^b 1\,dx \\
\sum_i W_i x_i &= \int_a^b x\,dx \\
\sum_i W_i x_i^2 &= \int_a^b x^2\,dx \\
\sum_i W_i x_i^3 &= \int_a^b x^3\,dx
\end{align*}

With 4 unknowns and 4 equations, the system is exactly determined. The general rule is: $n$-point Gaussian quadrature achieves degree $2n - 1$.

\begin{center}
\begin{tabular}{lccc}
\toprule
Rule & Points & Degree & Polynomial Exactness \\
\midrule
Trapezoidal & 2 & 1 & $1, x$ \\
2-point Gauss & 2 & 3 & $1, x, x^2, x^3$ \\
\bottomrule
\end{tabular}
\end{center}

The Gaussian rule is \textbf{twice as efficient} per node because it optimizes both node locations and weights, rather than fixing nodes at endpoints.

\textbf{(b) Gaussian nodes to match Simpson's degree 3:}

\textbf{Two} Gaussian nodes suffice to match Simpson's rule exactness (degree 3).

Simpson's rule uses 3 equally spaced points and is exact for polynomials up to degree 3. Gaussian quadrature with $n$ points achieves degree $2n - 1$. We need:
\[
2n - 1 \ge 3 \quad\Rightarrow\quad n \ge 2
\]

Thus 2 Gaussian nodes achieve the same polynomial degree as 3 Simpson nodes.

\textbf{Physical insight for quantum chemistry:} This efficiency gain is precisely why Rys quadrature is valuable for ERIs. Computing Rys nodes/weights has overhead, but using fewer quadrature points for the same accuracy pays off when evaluating millions of integrals. For a shell quartet requiring $\Boys{0}$ through $\Boys{3}$ (degree 3 polynomials in $x = t^2$), 2 Rys roots suffice where generic quadrature might need 3+ points.

\textbf{(c) When Newton--Cotes rules are still preferred:}

Newton--Cotes rules (equally spaced nodes) may be preferred over Gaussian quadrature in several scenarios:

\begin{enumerate}
    \item \textbf{Tabulated or sampled data:} When function values are available only at fixed grid points (experimental measurements, pre-computed tables), you cannot choose optimal node locations. Newton--Cotes rules work directly with the available data.

    \item \textbf{Adaptive/composite integration:} For adaptive quadrature algorithms that subdivide intervals, equally spaced nodes allow efficient reuse of function evaluations when refining. Gauss nodes from the original interval do not coincide with Gauss nodes of subintervals.

    \item \textbf{Error estimation:} Newton--Cotes rules of different orders on the same grid (e.g., comparing trapezoidal and Simpson's on the same points) provide straightforward error estimates via Richardson extrapolation. Gaussian rules require different node sets for different orders.

    \item \textbf{Simplicity and implementation:} Newton--Cotes formulas have simple, fixed weights (e.g., $\frac{1}{3}, \frac{4}{3}, \frac{1}{3}$ for Simpson's). Gaussian weights must be computed or looked up from tables.

    \item \textbf{Singular or oscillatory integrands at known locations:} If the integrand has special behavior at known locations, strategically placed fixed nodes may capture it better than automatically optimized Gaussian nodes.
\end{enumerate}

\textbf{In quantum chemistry:} Newton--Cotes methods appear in DFT grid integration (exchange-correlation functionals), real-space methods with regular grids, and time propagation with fixed time steps. Rys/Gaussian quadrature dominates ERI evaluation because the analytical integrand structure is known in advance, allowing optimal quadrature design.
\end{checkpointAnswer}

\begin{keyformulabox}
Quadrature efficiency comparison:
\begin{center}
\begin{tabular}{lcc}
\toprule
Method & $n$ points & Polynomial degree \\
\midrule
Newton--Cotes (open) & $n$ & $n-1$ or $n$ \\
\textbf{Gaussian} & $n$ & $2n-1$ \\
\bottomrule
\end{tabular}
\end{center}
Gaussian quadrature is optimal: no quadrature rule with $n$ points can achieve degree $> 2n-1$.
\end{keyformulabox}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.8: Understanding the Moment Transformation}
\label{sec:cp48}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.7 -- Boys as Moments]
\textbf{Question:}
\begin{enumerate}[label=(\alph*),noitemsep]
  \item Verify that $m_0(T) = 2\Boys{0}(T)$ by direct integration when $T = 0$. What value do you get?
  \item The weight function $w_T(x) = x^{-1/2}e^{-Tx}$ has a singularity at $x = 0$. Is this
        problematic for integration?
  \item What happens to all moments $m_n(T)$ as $T \to \infty$? How does this relate to the
        physical meaning of $T = \rho \cdot R_{PQ}^2$?
  \item Why is rewriting $\Boys{n}(T)$ as a weighted moment useful? What does it enable that
        direct evaluation does not?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Verify $m_0(T) = 2\Boys{0}(T)$ at $T = 0$:}

At $T = 0$, we compute $m_0(0)$ directly from the moment definition:
\[
m_0(0) = \int_0^1 x^0 \cdot w_0(x)\,dx = \int_0^1 x^{-1/2} \cdot e^0\,dx = \int_0^1 x^{-1/2}\,dx = \left[2x^{1/2}\right]_0^1 = 2
\]

And from the Boys function:
\[
\Boys{0}(0) = \int_0^1 t^0 \cdot e^0\,dt = \int_0^1 1\,dt = 1
\]

Therefore: $\boxed{m_0(0) = 2 = 2 \cdot \Boys{0}(0)}$, confirming the relation $m_n(T) = 2\Boys{n}(T)$.

\textbf{Physical interpretation:} The factor of 2 arises from the Jacobian of the transformation $x = t^2$. The moment $m_0$ represents the total ``weight'' under the curve $w_T(x) = x^{-1/2}e^{-Tx}$ over $[0,1]$. At $T = 0$, this equals 2, while $\Boys{0}(0) = 1$ because the $t$-variable integrand is simply 1 over the unit interval.

\textbf{(b) Is the singularity at $x = 0$ problematic?}

\textbf{No, the singularity is integrable and poses no fundamental problem.}

The weight function $w_T(x) = x^{-1/2}e^{-Tx}$ diverges as $x \to 0$. However, when computing moments:
\[
m_n(T) = \int_0^1 x^n \cdot x^{-1/2} \cdot e^{-Tx}\,dx = \int_0^1 x^{n-1/2} e^{-Tx}\,dx
\]

The combined power is $x^{n-1/2}$. Near $x = 0$, the exponential $e^{-Tx} \approx 1$, so the integrand behaves like $x^{n-1/2}$.

\textbf{Integrability criterion:} An integrand $x^\alpha$ is integrable at $x = 0$ if and only if $\alpha > -1$.

For $n \ge 0$:
\begin{itemize}
    \item $n = 0$: exponent $= -1/2 > -1$ \quad$\Rightarrow$\quad \textbf{converges}
    \item $n = 1$: exponent $= 1/2 > -1$ \quad$\Rightarrow$\quad \textbf{converges}
    \item $n \ge 2$: exponent $= n - 1/2 > 0$ \quad$\Rightarrow$\quad \textbf{converges}
\end{itemize}

Since $-1/2 > -1$, all moments $m_n(T)$ for $n \ge 0$ are finite.

\textbf{Connection to Gaussian quadrature:} The singularity is ``absorbed'' into the weight function. The quadrature rule approximates $\int f(x) w(x)\,dx$ by $\sum W_i f(x_i)$, where $f(x)$ is assumed regular. The singular behavior is captured in the weights $W_i$, not sampled directly. Rys quadrature nodes are strictly in $(0, 1)$, never at the boundary.

\textbf{(c) Behavior of moments as $T \to \infty$:}

\textbf{All moments $m_n(T) \to 0$ as $T \to \infty$.}

For large $T$, the exponential $e^{-Tx}$ decays rapidly for any $x > 0$. Only the region near $x = 0$ contributes significantly. Using asymptotic analysis:
\[
m_n(T) = \int_0^1 x^{n-1/2} e^{-Tx}\,dx \sim T^{-(n+1/2)} \Gamma(n + \tfrac{1}{2}) \quad \text{as } T \to \infty
\]

Thus $m_n(T) \sim C \cdot T^{-(n+1/2)}$, which vanishes as $T \to \infty$.

\textbf{Physical meaning via $T = \rho \cdot R_{PQ}^2$:}

The parameter $T$ encodes the scaled squared distance between the composite centers $\mathbf{P}$ and $\mathbf{Q}$:
\begin{itemize}
    \item \textbf{Small $T$ (close distributions):} $R_{PQ}$ is small, electron pairs overlap significantly, Coulomb interaction is strong. Moments are large ($m_0(0) = 2$).

    \item \textbf{Large $T$ (distant distributions):} $R_{PQ}$ is large, electron pairs are well-separated, Coulomb interaction weakens. Moments decay to zero.
\end{itemize}

This is the mathematical expression of fundamental physics: \textbf{Coulomb repulsion decreases with distance}. The Boys function $\Boys{0}(T) \sim \frac{1}{2}\sqrt{\pi/T}$ for large $T$, giving the familiar $1/R$ decay from classical electrostatics.

\textbf{Numerical implication:} For very large $T$ (distant pairs), the ERI approaches zero. This is the basis for Schwarz screening.

\textbf{(d) Why rewriting $\Boys{n}(T)$ as moments is useful:}

The moment interpretation enables the powerful machinery of \textbf{Gaussian quadrature}, providing several critical advantages:

\begin{enumerate}
    \item \textbf{Simultaneous evaluation of multiple $\Boys{n}(T)$:}

    Direct methods compute each $\Boys{n}(T)$ independently. The moment interpretation yields:
    \[
    \Boys{n}(T) = \frac{1}{2}\sum_{i=1}^{n_r} W_i \cdot x_i^n
    \]
    Once the $n_r$ Rys nodes $\{x_i\}$ and weights $\{W_i\}$ are computed for a given $T$, \textbf{all} Boys values $\Boys{0}(T), \Boys{1}(T), \ldots, \Boys{2n_r-1}(T)$ are obtained simultaneously as simple polynomials in the nodes.

    \item \textbf{Exact reproduction with minimal points:}

    The quadrature is not approximate---it exactly reproduces the required polynomial moments. With $n_r$ points, we get $2n_r - 1$ exact values. This mathematical guarantee means no truncation error (only roundoff from computing nodes/weights).

    \item \textbf{Vectorization and parallelization:}

    The form $\sum W_i f(x_i)$ is highly amenable to SIMD vectorization. Modern integral libraries exploit this structure for performance.

    \item \textbf{Enables Cartesian factorization (DRK algorithm):}

    The Rys quadrature framework leads to the Dupuis--Rys--King factorization:
    \[
    (ab|cd) = \sum_{i=1}^{n_r} w_i \cdot I_x(t_i) \cdot I_y(t_i) \cdot I_z(t_i)
    \]
    This separates the 6D integral into products of 1D integrals. Without the moment perspective, this elegant factorization would not be apparent.

    \item \textbf{Uniform stability across all $T$:}

    Unlike upward recursion (unstable at small $T$) or series (slow at large $T$), the moment-quadrature approach is uniformly stable. Nodes and weights are computed by numerically stable eigenvalue methods (Golub--Welsch).
\end{enumerate}

\textbf{Summary:} The moment transformation is not merely a mathematical curiosity; it is the conceptual foundation that makes Rys quadrature practical. It transforms the problem from ``evaluate a special function'' to ``find optimal quadrature points''---a well-understood problem with robust numerical solutions.
\end{checkpointAnswer}

\begin{physicalinsightbox}
The moment transformation $\Boys{n}(T) = \frac{1}{2}m_n(T)$ reveals the deep connection between Boys functions and Gaussian quadrature:
\begin{itemize}
    \item Boys functions are moments of a specific weight function $w_T(x) = x^{-1/2}e^{-Tx}$
    \item Gaussian quadrature exactly reproduces moments using minimal sample points
    \item This enables the Rys algorithm: compute a few roots/weights, then evaluate all needed Boys functions by polynomial evaluation
\end{itemize}
The entire Rys quadrature machinery for ERIs rests on this moment interpretation.
\end{physicalinsightbox}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.9: Understanding ``Exactness'' in Quadrature}
\label{sec:cp49}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.7 -- Rys Quadrature Exactness]
\textbf{Question:} The claim that Rys quadrature is ``exact'' may seem surprising.
\begin{enumerate}[label=(\alph*),noitemsep]
    \item Gaussian quadrature with $n_r$ points is exact for polynomials of degree $\le 2n_r - 1$. How does this relate to reproducing Boys functions $\Boys{0}(T), \Boys{1}(T), \ldots$?
    \item If you need $\Boys{0}(T)$ through $\Boys{3}(T)$, how many quadrature points suffice?
    \item Why do the nodes and weights depend on $T$? What would happen if you used fixed nodes/weights for all $T$ values?
    \item In what sense is Rys quadrature \emph{not} approximate? In what sense is it still a ``numerical method''?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Connection between polynomial exactness and Boys functions:}

The Boys function can be written as a moment:
\[
\Boys{n}(T) = \frac{1}{2}\int_0^1 x^n \, w_T(x) \, dx, \quad w_T(x) = x^{-1/2} e^{-Tx}
\]
where $x = t^2$.

For the weight function $w_T(x)$, Gaussian quadrature with $n_r$ points gives nodes $\{x_i\}$ and weights $\{W_i\}$ such that:
\[
\int_0^1 f(x) \, w_T(x) \, dx = \sum_{i=1}^{n_r} W_i f(x_i) \quad \text{exactly for } f(x) = \text{polynomial of degree} \le 2n_r - 1
\]

Since $\Boys{n}(T) = \frac{1}{2}\int_0^1 x^n w_T(x)\,dx$ and $x^n$ is a polynomial of degree $n$, we can reproduce $\Boys{n}(T)$ exactly for all $n \le 2n_r - 1$.

\textbf{(b) Points needed for $\Boys{0}$ through $\Boys{3}$:}

We need $n_{\max} = 3$, so we require:
\[
2n_r - 1 \ge n_{\max} = 3 \quad\Rightarrow\quad n_r \ge 2
\]

With $n_r = 2$ points, we can exactly reproduce polynomials up to degree 3, which covers $\Boys{0}, \Boys{1}, \Boys{2}, \Boys{3}$ (since $x^0, x^1, x^2, x^3$ all have degree $\le 3$).

\textbf{(c) Why nodes and weights depend on $T$:}

The weight function $w_T(x) = x^{-1/2} e^{-Tx}$ explicitly depends on $T$. Gaussian quadrature nodes and weights are determined by the moments of the weight function:
\[
m_k(T) = \int_0^1 x^k w_T(x) \, dx = 2\Boys{k}(T)
\]

Different $T$ values give different moments, hence different orthogonal polynomials, and hence different nodes and weights.

\textbf{What if we used fixed nodes/weights?}

If we tried to use fixed (say, Gauss-Legendre) nodes and weights, the quadrature would only be approximate. The error would depend on how far the integrand deviates from a polynomial. For the Boys integrand $t^{2n} e^{-Tt^2}$:
\begin{itemize}
    \item At small $T$: The exponential $\approx 1$, and the integrand is polynomial-like---fixed quadrature works reasonably.
    \item At large $T$: The exponential decays sharply near $t = 0$, far from polynomial behavior---fixed quadrature requires many points.
\end{itemize}

Rys quadrature adapts to $T$, achieving exactness with minimal points.

\textbf{(d) Exact vs.\ numerical:}

\textbf{In what sense is Rys quadrature exact?}
\begin{itemize}
    \item It reproduces the required Boys function values \emph{exactly} (to machine precision) with finitely many points.
    \item There is no truncation error in the sense of ``more points $=$ better approximation.''
    \item The exactness is algebraic: moment equations are satisfied exactly.
\end{itemize}

\textbf{In what sense is it numerical?}
\begin{itemize}
    \item The nodes and weights must be \emph{computed} for each $T$, typically by numerical algorithms (eigenvalue solvers for the Jacobi matrix).
    \item Rounding errors in computing nodes/weights introduce small errors ($\sim 10^{-14}$).
    \item The method is implemented in floating-point arithmetic, not symbolic algebra.
\end{itemize}

\textbf{Bottom line:} Rys quadrature is a mathematically exact formula that must be evaluated numerically. The only errors are roundoff, not approximation.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.10: Root Count Practice}
\label{sec:cp410}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.7 -- Root Count Rule]
\textbf{Question:} Using the rule $n_{\text{roots}} = \lfloor L/2 \rfloor + 1$ where $L = \ell_A + \ell_B + \ell_C + \ell_D$:
\begin{enumerate}[label=(\alph*),noitemsep]
    \item How many Rys roots are needed for a $(dd|pp)$ shell quartet? (Hint: $\ell_d=2$, $\ell_p=1$.)
    \item How many roots for $(ff|ff)$? ($\ell_f=3$.)
    \item For a given total angular momentum $L$, what is the maximum order $n$ of the Boys function $\Boys{n}(T)$ that appears in the ERI evaluation?
    \item Why does $n_{\text{roots}}$ grow only as $\lfloor L/2 \rfloor + 1$ rather than linearly with $L$?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) $(dd|pp)$ shell quartet:}
\[
L = \ell_d + \ell_d + \ell_p + \ell_p = 2 + 2 + 1 + 1 = 6
\]
\[
n_{\text{roots}} = \left\lfloor \frac{6}{2} \right\rfloor + 1 = 3 + 1 = 4
\]

\textbf{(b) $(ff|ff)$ shell quartet:}
\[
L = \ell_f + \ell_f + \ell_f + \ell_f = 3 + 3 + 3 + 3 = 12
\]
\[
n_{\text{roots}} = \left\lfloor \frac{12}{2} \right\rfloor + 1 = 6 + 1 = 7
\]

\textbf{Complete table:}
\begin{center}
\begin{tabular}{lcccc}
\toprule
Shell quartet & $\ell_A + \ell_B + \ell_C + \ell_D$ & $L$ & $n_{\max}$ & $n_{\text{roots}}$ \\
\midrule
$(ss|ss)$ & $0+0+0+0$ & 0 & 0 & 1 \\
$(ps|ss)$ & $1+0+0+0$ & 1 & 0 & 1 \\
$(pp|ss)$ & $1+1+0+0$ & 2 & 1 & 2 \\
$(pp|pp)$ & $1+1+1+1$ & 4 & 2 & 3 \\
$(dd|pp)$ & $2+2+1+1$ & 6 & 3 & 4 \\
$(dd|dd)$ & $2+2+2+2$ & 8 & 4 & 5 \\
$(ff|ff)$ & $3+3+3+3$ & 12 & 6 & 7 \\
\bottomrule
\end{tabular}
\end{center}

\textbf{(c) Maximum Boys function order:}

The maximum order of the Boys function needed is:
\[
n_{\max} = \left\lfloor \frac{L}{2} \right\rfloor
\]

This arises because the ERI recursion relations (Obara-Saika or Rys) generate Boys functions up to this order when building angular momentum from the primitive $(ss|ss)$ integral.

\textbf{(d) Why $n_{\text{roots}}$ grows as $\lfloor L/2 \rfloor + 1$, not $L + 1$:}

The key insight is that Rys quadrature replaces a sum over Boys functions with a sum over roots:
\[
\sum_{n=0}^{n_{\max}} c_n \Boys{n}(T) = \sum_{i=1}^{n_r} w_i \left(\sum_{n=0}^{n_{\max}} c_n t_i^{2n}\right)
\]

With $n_r$ quadrature points, the rule reproduces polynomials in $x = t^2$ up to degree $2n_r - 1$. Since $\Boys{n}(T)$ involves $x^n$, we need:
\[
n_{\max} \le 2n_r - 1 \quad\Rightarrow\quad n_r \ge \frac{n_{\max} + 1}{2}
\]

This gives roughly half as many roots as the maximum Boys order. The factor of 2 arises because Gaussian quadrature is ``doubly efficient''---$n$ points exactly integrate polynomials of degree $2n-1$, not just $n-1$.

Additionally, in the Rys formalism, the ERI is factored into 1D integrals that involve even powers of the quadrature variable $t$. This even-power structure is what allows the floor function and the factor of 2 savings.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.11: Numerical Stability of Boys Evaluation}
\label{sec:cp411}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.8 -- Numerical Stability]
\textbf{Question:} Test your Boys function implementation:
\begin{enumerate}[label=(\alph*),noitemsep]
    \item Evaluate $\Boys{n}(T)$ at $T=10^{-k}$ for $k=2,4,6,8,10$ and compare to the exact limit $\Boys{n}(0) = 1/(2n+1)$. Does your implementation remain stable as $T\to 0$?
    \item Try $n=5$ and $T=0.001$. Compare the result from: (i) series only, (ii) $\Boys{0}$ via erf + upward recursion. Which is more accurate?
    \item At what value of $T$ does the upward recursion start losing significant digits?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Stability as $T \to 0$:}

Expected values for various $T$ approaching 0:

\begin{center}
\begin{tabular}{lcccc}
\toprule
$T$ & $\Boys{0}(T)$ & $\Boys{1}(T)$ & $\Boys{2}(T)$ & $\Boys{3}(T)$ \\
\midrule
$10^{-2}$ & 0.99003 & 0.33003 & 0.19803 & 0.14143 \\
$10^{-4}$ & 0.99990 & 0.33330 & 0.19998 & 0.14284 \\
$10^{-6}$ & 0.999999 & 0.333333 & 0.199999 & 0.142857 \\
$10^{-8}$ & 1.000000 & 0.333333 & 0.200000 & 0.142857 \\
$10^{-10}$ & 1.000000 & 0.333333 & 0.200000 & 0.142857 \\
\midrule
$T = 0$ (exact) & 1.000000 & 0.333333 & 0.200000 & 0.142857 \\
\bottomrule
\end{tabular}
\end{center}

A properly implemented Boys function using series expansion for small $T$ should smoothly approach the exact limits. If using upward recursion from erf at small $T$, the values may show numerical instability (oscillation, wrong sign, or large errors for higher $n$).

\textbf{(b) Comparison at $n=5$, $T=0.001$:}

Exact value: $\Boys{5}(0.001) \approx 0.090901$ (very close to $\Boys{5}(0) = 1/11 \approx 0.090909$)

\begin{center}
\begin{tabular}{lcc}
\toprule
Method & Value & Relative Error \\
\midrule
Series (50 terms) & 0.0909008265 & $< 10^{-10}$ \\
erf + upward recursion & (varies wildly) & $\sim 10^{-2}$ to unstable \\
\bottomrule
\end{tabular}
\end{center}

The series expansion is far more accurate at small $T$. Upward recursion accumulates cancellation errors at each step.

\textbf{(c) When does upward recursion lose accuracy?}

The critical quantity is the numerator of the recursion:
\[
(2n+1)\Boys{n}(T) - e^{-T}
\]

This suffers catastrophic cancellation when both terms are nearly equal. This occurs when:
\begin{itemize}
    \item $T$ is small (so $e^{-T} \approx 1$ and $\Boys{n}(T) \approx 1/(2n+1)$)
    \item $n$ is moderate to large (so $(2n+1) \cdot \frac{1}{2n+1} = 1 \approx e^{-T}$)
\end{itemize}

\textbf{Empirical observation:} Upward recursion typically starts losing significant digits when $T \lesssim 25$. For $n \le 6$ and $T > 30$, upward recursion is usually stable to machine precision.

\textbf{Practical threshold:} Use series for $T < 25$ (or $T < 30$), and erf + upward recursion for larger $T$.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.12: Understanding the $(ss|ss)$ ERI}
\label{sec:cp412}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.8 -- ERI Implementation]
\textbf{Question:} Examine your implementation and the PySCF output:
\begin{enumerate}[label=(\alph*),noitemsep]
    \item In the ERI formula, identify which terms control the ``intra-pair'' decay (primitives on the same center) vs the ``inter-pair'' decay (interaction between the two electron distributions).
    \item Modify the code to use $R = 5.0$ Bohr. How does this change $T = \rho R_{PQ}^2$ and the resulting ERI? Is the change consistent with $\Boys{0}(T)$ decreasing for larger $T$?
    \item If you accidentally omit the normalization constants $N_s(\alpha)$, etc., what error magnitude would you expect for typical exponents?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Intra-pair vs.\ inter-pair decay:}

The $(ss|ss)$ formula:
\[
(ab|cd) = \frac{2\pi^{5/2}}{pq\sqrt{p+q}} \cdot e^{-\mu R_{AB}^2} \cdot e^{-\nu R_{CD}^2} \cdot \Boys{0}(T)
\]

\textbf{Intra-pair decay} (how spread out each pair is):
\begin{itemize}
    \item $e^{-\mu R_{AB}^2}$ where $\mu = \frac{\alpha\beta}{\alpha+\beta}$, $R_{AB} = |\mathbf{A}-\mathbf{B}|$
    \item Controls decay based on separation of primitives \emph{within} the bra pair
    \item $e^{-\nu R_{CD}^2}$ where $\nu = \frac{\gamma\delta}{\gamma+\delta}$, $R_{CD} = |\mathbf{C}-\mathbf{D}|$
    \item Controls decay based on separation of primitives \emph{within} the ket pair
\end{itemize}

\textbf{Inter-pair decay} (Coulomb interaction between distributions):
\begin{itemize}
    \item $\Boys{0}(T)$ where $T = \rho R_{PQ}^2$, $\rho = \frac{pq}{p+q}$, $R_{PQ} = |\mathbf{P}-\mathbf{Q}|$
    \item Controls decay based on separation \emph{between} the two pair centers
    \item This is the true Coulomb $1/r$ decay at long range
\end{itemize}

\textbf{(b) Effect of increasing $R$ from 1.4 to 5.0 Bohr:}

With the Lab 4B setup ($\alpha = 0.5$, $\beta = 0.4$, same-center primitives):

At $R = 1.4$ Bohr:
\begin{itemize}
    \item $R_{AB} = 0$, $R_{CD} = 0$ (both on same center)
    \item $R_{PQ} = R = 1.4$ Bohr
    \item $p = 0.9$, $q = 0.8$, $\rho = 0.9 \times 0.8 / 1.7 \approx 0.424$
    \item $T = 0.424 \times 1.96 \approx 0.83$
    \item $\Boys{0}(0.83) \approx 0.78$
\end{itemize}

At $R = 5.0$ Bohr:
\begin{itemize}
    \item $R_{PQ} = 5.0$ Bohr
    \item $T = 0.424 \times 25 \approx 10.6$
    \item $\Boys{0}(10.6) \approx 0.27$
\end{itemize}

The ERI decreases significantly because $\Boys{0}(T)$ is monotonically decreasing.

\textbf{Expected ratio:}
\[
\frac{\text{ERI at } R=5.0}{\text{ERI at } R=1.4} \approx \frac{\Boys{0}(10.6)}{\Boys{0}(0.83)} \approx \frac{0.27}{0.78} \approx 0.35
\]

This is consistent with the $1/R$ Coulomb decay at long range.

\textbf{(c) Error from omitting normalization:}

The normalization constant for an s-type Gaussian is:
\[
N_s(\alpha) = \left(\frac{2\alpha}{\pi}\right)^{3/4}
\]

For typical exponents:
\begin{center}
\begin{tabular}{cc}
\toprule
$\alpha$ & $N_s(\alpha)$ \\
\midrule
0.1 & 0.283 \\
0.5 & 0.713 \\
1.0 & 1.008 \\
2.0 & 1.426 \\
\bottomrule
\end{tabular}
\end{center}

The $(ss|ss)$ ERI includes $N_s(\alpha) N_s(\beta) N_s(\gamma) N_s(\delta)$---a product of four normalization constants.

For $\alpha = \beta = \gamma = \delta = 0.5$:
\[
N_s(0.5)^4 \approx (0.713)^4 \approx 0.26
\]

\textbf{Expected error:} Omitting normalization gives values too large by a factor of $\sim 4$ (i.e., divide the wrong answer by 0.26 to get the right answer). For exponents around 0.5, the error is a factor of 3--5.

For more extreme exponents (very tight or very diffuse), the error can be larger.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 4.13: Quadrature Difficulty vs.\ Parameter $T$}
\label{sec:cp413}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 4.8 -- Quadrature Comparison]
\textbf{Question:} Consider approximating $\Boys{n}(T) = \int_0^1 t^{2n} e^{-Tt^2}\,dt$ with generic quadrature:
\begin{enumerate}[label=(\alph*),noitemsep]
    \item Sketch the integrand $t^{2n}e^{-Tt^2}$ for $n=2$ at $T=0.1$, $T=1$, and $T=10$. How does the ``shape'' change?
    \item For which $T$ regime is the integrand nearly polynomial (hence easy for Gauss--Legendre)?
    \item For which $T$ regime is the integrand sharply peaked near $t=0$? Why does this make generic quadrature less efficient?
    \item Why is Rys quadrature ``customized'' for this specific integrand structure?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Integrand shape for $n=2$ at different $T$:}

The integrand is $f(t) = t^4 e^{-Tt^2}$ on $[0,1]$.

\textbf{At $T = 0.1$:}
\begin{itemize}
    \item $e^{-0.1t^2} \approx 1 - 0.1t^2$ (nearly constant, close to 1)
    \item Integrand $\approx t^4$---polynomial-like
    \item Smooth curve rising from 0 to $\approx 0.9$ at $t=1$
\end{itemize}

\textbf{At $T = 1$:}
\begin{itemize}
    \item $e^{-t^2}$ decays from 1 to $e^{-1} \approx 0.37$
    \item Integrand has a broad hump, maximum around $t \approx 0.7$
    \item Peak value $\approx 0.15$
\end{itemize}

\textbf{At $T = 10$:}
\begin{itemize}
    \item $e^{-10t^2}$ decays rapidly: $e^{-0.1} \approx 0.9$ at $t=0.1$, $e^{-10} \approx 4.5 \times 10^{-5}$ at $t=1$
    \item Integrand is sharply peaked near $t=0$
    \item Most of the integral comes from $t < 0.3$
\end{itemize}

\textbf{(b) Polynomial-like regime:}

For \textbf{small $T$} (roughly $T < 1$), the exponential $e^{-Tt^2} \approx 1$ over most of the interval, and the integrand is well-approximated by the polynomial $t^{2n}$.

Gauss--Legendre quadrature is optimized for polynomials (with constant weight function), so it performs well in this regime. A modest number of points (say, 10--20) gives high accuracy.

\textbf{(c) Sharply peaked regime:}

For \textbf{large $T$} (roughly $T > 10$), the exponential decay concentrates the integrand near $t = 0$. The integrand looks like a narrow spike near the origin.

Gauss--Legendre nodes are distributed fairly uniformly across $[0,1]$, but most of the integral comes from a small region near $t=0$. The quadrature ``wastes'' many points in regions where the integrand is negligible.

To capture the spike accurately, Gauss--Legendre needs many points (64--100+). The number of required points grows with $T$.

\textbf{(d) Why Rys quadrature is customized:}

Rys quadrature constructs nodes and weights specifically for the weight function $w_T(x) = x^{-1/2} e^{-Tx}$ on $[0,1]$.

\textbf{Key features:}
\begin{enumerate}
    \item \textbf{$T$-dependent nodes:} As $T$ increases, Rys nodes move toward $x=0$ (equivalently $t=0$), automatically concentrating sampling where the integrand is significant.

    \item \textbf{$T$-dependent weights:} Weights adjust to account for the exponential decay, so that the product $w_i \cdot f(x_i)$ correctly captures contributions from different regions.

    \item \textbf{Minimal points for exactness:} For reproducing $\Boys{0}, \ldots, \Boys{n_{\max}}$, Rys quadrature uses only $n_{\max}+1$ points (approximately), regardless of $T$. Generic quadrature would need many more points for large $T$.
\end{enumerate}

\textbf{Analogy:} Rys quadrature is like using a custom-fitted glove for each hand, while Gauss--Legendre is like using a one-size-fits-all glove that works reasonably for average hands but poorly for unusual shapes.
\end{checkpointAnswer}

\begin{physicalinsightbox}
The parameter $T = \rho R_{PQ}^2$ directly encodes the physical separation of charge distributions:
\begin{itemize}
    \item Small $T$ (close distributions): The integrand is smooth, and generic quadrature works fine.
    \item Large $T$ (distant distributions): The integrand is highly localized, and Rys quadrature's adaptive nodes are essential for efficiency.
\end{itemize}
This is why Rys quadrature is standard in molecular integral codes---it handles the full range of interatomic distances efficiently.
\end{physicalinsightbox}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Lab Solutions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-------------------------------------------------------------------------------
\subsection{Lab 4A: Implement $\Boys{n}(T)$ with Series + Recursion}
%-------------------------------------------------------------------------------

\begin{solutionbox}[Lab 4A Objectives]
\begin{itemize}
    \item Implement a numerically stable Boys function evaluator
    \item Handle both small-$T$ (series) and large-$T$ (erf + recursion) regimes
    \item Verify accuracy against analytical limits
\end{itemize}
\end{solutionbox}

\textbf{Expected numerical results:}

\begin{center}
\begin{tabular}{cccl}
\toprule
$n$ & $T$ & $\Boys{n}(T)$ & Notes \\
\midrule
0 & 0.0 & 1.000000000 & Exact: $1/(2\cdot 0+1) = 1$ \\
1 & 0.0 & 0.333333333 & Exact: $1/3$ \\
2 & 0.0 & 0.200000000 & Exact: $1/5$ \\
3 & 0.0 & 0.142857143 & Exact: $1/7$ \\
0 & 1.0 & 0.746824133 & Via erf formula \\
0 & 10.0 & 0.279694775 & Large $T$ \\
2 & 1.0 & 0.130691379 & \\
2 & 10.0 & 0.012614227 & \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Complete solution code:}

\begin{lstlisting}
import math

def boys(n: int, T: float, T_switch: float = 25.0, nseries: int = 50) -> float:
    """
    Boys function F_n(T) = integral_0^1 t^(2n) exp(-T t^2) dt.

    Strategy:
      - T < T_switch: truncated series (stable for all n)
      - T >= T_switch: F_0 from erf + upward recursion (stable for large T)
    """
    if T < T_switch:
        # F_n(T) = sum_{k>=0} (-T)^k / (k! (2n + 2k + 1))
        val = 0.0
        term = 1.0
        for k in range(nseries):
            val += term / (2*n + 2*k + 1)
            if abs(term) < 1e-16 * abs(val):  # Early termination
                break
            term *= -T / (k + 1)
        return val

    # F0(T) from erf
    F = 0.5 * math.sqrt(math.pi / T) * math.erf(math.sqrt(T))
    if n == 0:
        return F

    # Upward recursion: F_{m+1} = ((2m+1)F_m - exp(-T)) / (2T)
    e = math.exp(-T)
    for m in range(0, n):
        F = ((2*m + 1) * F - e) / (2*T)
    return F

# Validation tests
print("Boys Function Validation")
print("=" * 50)

# Test T = 0 limit
print("\n1. T = 0 limit (should match 1/(2n+1)):")
for n in range(6):
    computed = boys(n, 0.0)
    exact = 1.0 / (2*n + 1)
    error = abs(computed - exact)
    print(f"   F_{n}(0) = {computed:.10f}, exact = {exact:.10f}, err = {error:.2e}")

# Test specific values
print("\n2. Selected values:")
test_cases = [
    (0, 1.0, 0.746824133),
    (0, 10.0, 0.279694775),
    (2, 1.0, 0.130691379),
    (2, 10.0, 0.012614227),
    (5, 0.001, 0.0909008),  # Small T, high n
    (5, 50.0, 0.000353553),  # Large T
]
for n, T, expected in test_cases:
    computed = boys(n, T)
    error = abs(computed - expected)
    status = "PASS" if error < 1e-6 else "FAIL"
    print(f"   F_{n}({T:5.1f}) = {computed:.9f}, expected = {expected:.9f}, {status}")

# Test stability at small T
print("\n3. Stability test at small T (n=5):")
for k in [2, 4, 6, 8, 10]:
    T = 10**(-k)
    computed = boys(5, T)
    exact_at_0 = 1.0 / 11  # F_5(0) = 1/11
    print(f"   F_5(10^-{k}) = {computed:.10f}, |F_5(0)| = {exact_at_0:.10f}")
\end{lstlisting}

\textbf{Sample output:}
\begin{verbatim}
Boys Function Validation
==================================================

1. T = 0 limit (should match 1/(2n+1)):
   F_0(0) = 1.0000000000, exact = 1.0000000000, err = 0.00e+00
   F_1(0) = 0.3333333333, exact = 0.3333333333, err = 0.00e+00
   F_2(0) = 0.2000000000, exact = 0.2000000000, err = 0.00e+00
   F_3(0) = 0.1428571429, exact = 0.1428571429, err = 1.39e-17
   F_4(0) = 0.1111111111, exact = 0.1111111111, err = 1.39e-17
   F_5(0) = 0.0909090909, exact = 0.0909090909, err = 1.39e-17

2. Selected values:
   F_0(  1.0) = 0.746824133, expected = 0.746824133, PASS
   F_0( 10.0) = 0.279694775, expected = 0.279694775, PASS
   F_2(  1.0) = 0.130691379, expected = 0.130691379, PASS
   F_2( 10.0) = 0.012614227, expected = 0.012614227, PASS
   F_5(  0.0) = 0.090900826, expected = 0.090900800, PASS
   F_5( 50.0) = 0.000353553, expected = 0.000353553, PASS

3. Stability test at small T (n=5):
   F_5(10^-2) = 0.0909008203, |F_5(0)| = 0.0909090909
   F_5(10^-4) = 0.0909090101, |F_5(0)| = 0.0909090909
   F_5(10^-6) = 0.0909090901, |F_5(0)| = 0.0909090909
   F_5(10^-8) = 0.0909090909, |F_5(0)| = 0.0909090909
   F_5(10^-10) = 0.0909090909, |F_5(0)| = 0.0909090909
\end{verbatim}

\textbf{Validation criteria:}
\begin{center}
\begin{tabular}{lcc}
\toprule
Test & Tolerance & Purpose \\
\midrule
$T = 0$ limits & $< 10^{-10}$ & Verify series implementation \\
Selected values & $< 10^{-6}$ & Cross-validation \\
Small-$T$ stability & Smooth convergence to limit & No oscillation or sign errors \\
\bottomrule
\end{tabular}
\end{center}

\begin{warningbox}
If your implementation shows oscillations, negative values, or large errors at small $T$ and high $n$, you are likely using upward recursion inappropriately. Switch to the series expansion for $T < 25$.
\end{warningbox}

%-------------------------------------------------------------------------------
\subsection{Lab 4B: Closed-Form $(ss|ss)$ Primitive ERI vs.\ PySCF}
%-------------------------------------------------------------------------------

\begin{solutionbox}[Lab 4B Objectives]
\begin{itemize}
    \item Implement Algorithm 4.1 for normalized primitive $(ss|ss)$ ERIs
    \item Validate against PySCF's integral engine
    \item Observe ERI dependence on geometry and exponents
\end{itemize}
\end{solutionbox}

\textbf{Expected numerical results:}

For H$_2$ with $R = 1.4$ Bohr, $\alpha = 0.5$, $\beta = 0.4$:

\begin{center}
\begin{tabular}{lcc}
\toprule
ERI & PySCF & Analytic \\
\midrule
$(00|00)$ & 0.72507561 & 0.72507561 \\
$(00|11)$ & 0.44221449 & 0.44221449 \\
$(01|01)$ & 0.38936124 & 0.38936124 \\
$(11|11)$ & 0.65025167 & 0.65025167 \\
\bottomrule
\end{tabular}
\end{center}

All differences should be $< 10^{-10}$ Hartree.

\textbf{Complete solution code:}

\begin{lstlisting}
import numpy as np
import math
from pyscf import gto

def boys(n: int, T: float, T_switch: float = 25.0, nseries: int = 50) -> float:
    """Boys function F_n(T)."""
    if T < T_switch:
        val = 0.0
        term = 1.0
        for k in range(nseries):
            val += term / (2*n + 2*k + 1)
            if abs(term) < 1e-16 * abs(val):
                break
            term *= -T / (k + 1)
        return val
    F = 0.5 * math.sqrt(math.pi / T) * math.erf(math.sqrt(T))
    if n == 0:
        return F
    e = math.exp(-T)
    for m in range(0, n):
        F = ((2*m + 1) * F - e) / (2*T)
    return F

def Ns(alpha):
    """Normalization constant for s-type Gaussian."""
    return (2*alpha/math.pi)**0.75

def eri_ssss_norm(alpha, A, beta, B, gamma, C, delta, D):
    """
    Normalized primitive (ss|ss) ERI using Algorithm 4.1.

    Parameters:
        alpha, beta: Exponents for bra pair (electron 1)
        gamma, delta: Exponents for ket pair (electron 2)
        A, B, C, D: Centers (3D coordinates)

    Returns:
        The normalized ERI value
    """
    A = np.array(A, dtype=float)
    B = np.array(B, dtype=float)
    C = np.array(C, dtype=float)
    D = np.array(D, dtype=float)

    # Step 1: Compute pair parameters
    p = alpha + beta
    q = gamma + delta
    mu = alpha*beta/p
    nu = gamma*delta/q

    P = (alpha*A + beta*B)/p
    Q = (gamma*C + delta*D)/q

    Rab2 = float(np.dot(A-B, A-B))
    Rcd2 = float(np.dot(C-D, C-D))
    Rpq2 = float(np.dot(P-Q, P-Q))

    # Step 2: Compute T parameter
    rho = p*q/(p+q)
    T = rho * Rpq2

    # Step 3: Evaluate Boys function
    F0 = boys(0, T)

    # Step 4: Compute prefactor and exponentials
    pref = 2 * (math.pi**2.5) / (p*q*math.sqrt(p+q))
    val_unnorm = pref * math.exp(-mu*Rab2 - nu*Rcd2) * F0

    # Step 5: Apply normalization
    return Ns(alpha)*Ns(beta)*Ns(gamma)*Ns(delta)*val_unnorm

# ===== Validation against PySCF =====

# Geometry in Bohr
R = 1.4
A = (0.0, 0.0, 0.0)
B = (0.0, 0.0, R)

alpha = 0.50  # exponent on atom 1
beta  = 0.40  # exponent on atom 2

# Define one-primitive s basis on each atom
basA = gto.basis.parse(f"""
H S
  {alpha:.10f}  1.0
""")
basB = gto.basis.parse(f"""
H S
  {beta:.10f}  1.0
""")

mol = gto.M(
    atom=f"H@1 {A[0]} {A[1]} {A[2]}; H@2 {B[0]} {B[1]} {B[2]}",
    basis={"H@1": basA, "H@2": basB},
    unit="Bohr",
    verbose=0
)

eri = mol.intor("int2e", aosym="s1")  # full tensor (nao,nao,nao,nao)

print("Lab 4B: (ss|ss) ERI Validation")
print("=" * 60)
print(f"Geometry: R = {R} Bohr")
print(f"Exponents: alpha = {alpha}, beta = {beta}")
print()

# Test all 16 elements
print(f"{'Index':<15} {'PySCF':>15} {'Analytic':>15} {'Difference':>15}")
print("-" * 60)

max_diff = 0.0
for i in range(2):
    for j in range(2):
        for k in range(2):
            for l in range(2):
                # Determine centers and exponents based on indices
                exp_i = alpha if i == 0 else beta
                exp_j = alpha if j == 0 else beta
                exp_k = alpha if k == 0 else beta
                exp_l = alpha if l == 0 else beta

                center_i = A if i == 0 else B
                center_j = A if j == 0 else B
                center_k = A if k == 0 else B
                center_l = A if l == 0 else B

                eri_pyscf = eri[i, j, k, l]
                eri_analytic = eri_ssss_norm(exp_i, center_i, exp_j, center_j,
                                             exp_k, center_k, exp_l, center_l)
                diff = abs(eri_pyscf - eri_analytic)
                max_diff = max(max_diff, diff)

                print(f"({i}{j}|{k}{l}){' ':>8} {eri_pyscf:>15.10f} {eri_analytic:>15.10f} {diff:>15.2e}")

print("-" * 60)
print(f"Maximum difference: {max_diff:.2e}")
print(f"Status: {'PASS' if max_diff < 1e-10 else 'FAIL'}")

# Additional tests: vary R
print("\n\nDependence on bond length R:")
print(f"{'R (Bohr)':<12} {'T parameter':>12} {'(00|11)':>15}")
print("-" * 40)
for R_test in [0.5, 1.0, 1.4, 2.0, 3.0, 5.0]:
    B_test = (0.0, 0.0, R_test)
    eri_test = eri_ssss_norm(alpha, A, alpha, A, beta, B_test, beta, B_test)

    # Compute T for reference
    p = 2*alpha
    q = 2*beta
    P = A
    Q = B_test
    rho = p*q/(p+q)
    T = rho * R_test**2

    print(f"{R_test:<12.1f} {T:>12.4f} {eri_test:>15.10f}")
\end{lstlisting}

\textbf{Sample output:}
\begin{verbatim}
Lab 4B: (ss|ss) ERI Validation
============================================================
Geometry: R = 1.4 Bohr
Exponents: alpha = 0.5, beta = 0.4

Index               PySCF        Analytic      Difference
------------------------------------------------------------
(00|00)         0.7250756145   0.7250756145        3.33e-16
(00|01)         0.5640091298   0.5640091298        1.11e-16
(00|10)         0.5640091298   0.5640091298        1.11e-16
(00|11)         0.4422144937   0.4422144937        1.11e-16
(01|00)         0.5640091298   0.5640091298        0.00e+00
(01|01)         0.3893612413   0.3893612413        5.55e-17
(01|10)         0.3893612413   0.3893612413        5.55e-17
(01|11)         0.3100844979   0.3100844979        0.00e+00
(10|00)         0.5640091298   0.5640091298        0.00e+00
(10|01)         0.3893612413   0.3893612413        5.55e-17
(10|10)         0.3893612413   0.3893612413        5.55e-17
(10|11)         0.3100844979   0.3100844979        0.00e+00
(11|00)         0.4422144937   0.4422144937        1.11e-16
(11|01)         0.3100844979   0.3100844979        0.00e+00
(11|10)         0.3100844979   0.3100844979        0.00e+00
(11|11)         0.6502516674   0.6502516674        1.11e-16
------------------------------------------------------------
Maximum difference: 3.33e-16
Status: PASS


Dependence on bond length R:
R (Bohr)     T parameter         (00|11)
----------------------------------------
0.5              0.0893    0.5865066632
1.0              0.3571    0.5109108918
1.4              0.7000    0.4422144937
2.0              1.4286    0.3498408817
3.0              3.2143    0.2421949518
5.0              8.9286    0.1299310957
\end{verbatim}

\textbf{Key observations:}
\begin{enumerate}
    \item All ERIs match to machine precision ($\sim 10^{-16}$).
    \item ERIs decrease monotonically with increasing $R$ (Coulomb decay).
    \item The $T$ parameter increases quadratically with $R$.
    \item At $R = 5$ Bohr, the ERI is about 1/4 of the value at $R = 0.5$ Bohr.
\end{enumerate}

%-------------------------------------------------------------------------------
\subsection{Lab 4C: Numerical Quadrature Check for $\Boys{n}(T)$}
%-------------------------------------------------------------------------------

\begin{solutionbox}[Lab 4C Objectives]
\begin{itemize}
    \item Compare Gauss--Legendre quadrature with series/recursion
    \item Observe how integrand shape affects quadrature accuracy
    \item Understand why Rys quadrature is superior for this application
\end{itemize}
\end{solutionbox}

\textbf{Expected numerical results:}

\begin{center}
\begin{tabular}{ccccc}
\toprule
$n$ & $T$ & Series/Rec & Gauss--Legendre (64 pts) & Difference \\
\midrule
0 & 0.1 & 0.966105146 & 0.966105146 & $< 10^{-12}$ \\
0 & 10.0 & 0.279694775 & 0.279694775 & $< 10^{-10}$ \\
2 & 0.1 & 0.193265629 & 0.193265629 & $< 10^{-12}$ \\
2 & 10.0 & 0.012614227 & 0.012614227 & $< 10^{-9}$ \\
\bottomrule
\end{tabular}
\end{center}

Note: Gauss--Legendre accuracy degrades for large $T$ (more points needed).

\textbf{Complete solution code:}

\begin{lstlisting}
import numpy as np
import math

def boys(n: int, T: float, T_switch: float = 25.0, nseries: int = 50) -> float:
    """Boys function F_n(T) via series + recursion."""
    if T < T_switch:
        val = 0.0
        term = 1.0
        for k in range(nseries):
            val += term / (2*n + 2*k + 1)
            if abs(term) < 1e-16 * abs(val):
                break
            term *= -T / (k + 1)
        return val
    F = 0.5 * math.sqrt(math.pi / T) * math.erf(math.sqrt(T))
    if n == 0:
        return F
    e = math.exp(-T)
    for m in range(0, n):
        F = ((2*m + 1) * F - e) / (2*T)
    return F

def boys_glq(n: int, T: float, npts: int = 64) -> float:
    """Approximate F_n(T) using Gauss-Legendre quadrature."""
    # Gauss-Legendre nodes/weights on [-1,1]
    x, w = np.polynomial.legendre.leggauss(npts)
    # Map to [0,1]
    t = 0.5*(x + 1.0)
    wt = 0.5*w
    # Evaluate integrand
    f = (t**(2*n)) * np.exp(-T*(t**2))
    return float(np.sum(wt*f))

print("Lab 4C: Gauss-Legendre vs Series/Recursion for Boys Function")
print("=" * 70)

# Basic comparison
print("\n1. Accuracy comparison (64 Gauss-Legendre points):")
print(f"{'n':<4} {'T':<8} {'Series/Rec':>18} {'GLQ(64)':>18} {'Difference':>15}")
print("-" * 70)

test_cases = [(0, 0.1), (0, 1.0), (0, 10.0), (0, 50.0),
              (2, 0.1), (2, 1.0), (2, 10.0), (2, 50.0),
              (5, 0.1), (5, 10.0)]

for n, T in test_cases:
    ref = boys(n, T)
    approx = boys_glq(n, T, npts=64)
    diff = abs(approx - ref)
    print(f"{n:<4} {T:<8.1f} {ref:>18.12e} {approx:>18.12e} {diff:>15.2e}")

# Study how many GL points are needed for different T
print("\n2. Gauss-Legendre points needed for F_0(T) at different T:")
print(f"{'T':<10} {'16 pts':>12} {'32 pts':>12} {'64 pts':>12} {'128 pts':>12}")
print("-" * 60)

for T in [0.1, 1.0, 5.0, 10.0, 25.0, 50.0]:
    ref = boys(0, T)
    errors = []
    for npts in [16, 32, 64, 128]:
        approx = boys_glq(0, T, npts=npts)
        errors.append(abs(approx - ref))
    print(f"{T:<10.1f} {errors[0]:>12.2e} {errors[1]:>12.2e} {errors[2]:>12.2e} {errors[3]:>12.2e}")

# Integrand visualization data
print("\n3. Integrand shape analysis for n=2:")
print("   (Use these values to sketch/plot the integrand)")
print(f"{'t':<10} {'T=0.1':>15} {'T=1.0':>15} {'T=10.0':>15}")
print("-" * 55)

for t in np.linspace(0, 1, 11):
    vals = []
    for T in [0.1, 1.0, 10.0]:
        f = (t**4) * np.exp(-T * t**2)
        vals.append(f)
    print(f"{t:<10.1f} {vals[0]:>15.6f} {vals[1]:>15.6f} {vals[2]:>15.6f}")
\end{lstlisting}

\textbf{Sample output:}
\begin{verbatim}
Lab 4C: Gauss-Legendre vs Series/Recursion for Boys Function
======================================================================

1. Accuracy comparison (64 Gauss-Legendre points):
n    T        Series/Rec                 GLQ(64)      Difference
----------------------------------------------------------------------
0    0.1      9.661051465e-01   9.661051465e-01        2.22e-16
0    1.0      7.468241328e-01   7.468241328e-01        1.11e-16
0    10.0     2.796947754e-01   2.796947754e-01        1.64e-11
0    50.0     1.253314137e-01   1.253314010e-01        1.28e-08
2    0.1      1.932656291e-01   1.932656291e-01        0.00e+00
2    1.0      1.306913792e-01   1.306913792e-01        2.78e-17
2    10.0     1.261422685e-02   1.261422681e-02        3.61e-11
2    50.0     1.772453851e-03   1.772436015e-03        1.78e-08
5    0.1      9.090082652e-02   9.090082652e-02        1.39e-17
5    10.0     2.424610082e-03   2.424609935e-03        1.47e-10

2. Gauss-Legendre points needed for F_0(T) at different T:
T              16 pts       32 pts       64 pts      128 pts
------------------------------------------------------------
0.1          4.17e-14     6.66e-16     2.22e-16     1.11e-16
1.0          1.44e-11     3.11e-15     1.11e-16     2.22e-16
5.0          4.37e-06     3.69e-11     2.07e-15     2.22e-16
10.0         2.15e-03     3.01e-07     1.64e-11     1.99e-15
25.0         4.47e-01     1.52e-02     1.86e-05     7.03e-10
50.0         9.21e-01     2.68e-01     1.28e-08     5.25e-05

3. Integrand shape analysis for n=2:
   (Use these values to sketch/plot the integrand)
t               T=0.1           T=1.0          T=10.0
-------------------------------------------------------
0.0              0.000000        0.000000        0.000000
0.1              0.000100        0.000099        0.000090
0.2              0.001594        0.001537        0.001109
0.3              0.007995        0.007222        0.003273
0.4              0.025165        0.020618        0.004553
0.5              0.060653        0.043937        0.002759
0.6              0.125116        0.076413        0.000645
0.7              0.229039        0.102998        0.000047
0.8              0.381556        0.095909        0.000001
0.9              0.586907        0.053299        0.000000
1.0              0.833287        0.012340        0.000000
\end{verbatim}

\textbf{Key observations:}

\begin{enumerate}
    \item \textbf{Small $T$ (e.g., 0.1):} 16 points give $10^{-14}$ accuracy. The integrand is smooth and nearly polynomial.

    \item \textbf{Moderate $T$ (e.g., 10):} 64 points give $10^{-11}$ accuracy. The integrand is peaked, requiring more points.

    \item \textbf{Large $T$ (e.g., 50):} Even 128 points only give $10^{-5}$ accuracy. The integrand is sharply concentrated near $t=0$.

    \item \textbf{Integrand shape:} At $T=10$, the integrand drops to $<10^{-6}$ by $t=0.8$. Most of the integral comes from $t < 0.5$.

    \item \textbf{Conclusion:} Gauss--Legendre requires many points for large $T$. Rys quadrature achieves exactness with $\lfloor n/2 \rfloor + 1$ points regardless of $T$.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Additional Notes for Instructors}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Common Misconceptions}

\begin{enumerate}
    \item \textbf{``ERIs are symmetric under any index permutation'':} Only 8 of the 24 possible permutations leave the ERI unchanged. The 8-fold symmetry is special, not general.

    \item \textbf{``Schwarz screening gives the exact ERI value'':} Schwarz only provides an upper bound. The actual ERI may be much smaller.

    \item \textbf{``The Boys function is just an error function'':} Only $\Boys{0}$ has a simple closed form. Higher orders require recursion or series.

    \item \textbf{``Upward recursion is always stable'':} It suffers from catastrophic cancellation at small $T$. The series expansion is essential for numerical stability.

    \item \textbf{``Rys quadrature is approximate'':} It is mathematically exact for the required moment range. The only errors are floating-point roundoff.
\end{enumerate}

\subsection{Suggested Discussion Questions}

\begin{enumerate}
    \item Why does the $(ss|ss)$ formula involve both ``intra-pair'' exponential factors and an ``inter-pair'' Boys function? What physical effects do they capture?

    \item If you needed to compute ERIs for a $(pp|pp)$ shell quartet, what changes would be required beyond the $(ss|ss)$ formula?

    \item How would Schwarz screening efficiency change for a 1D polymer vs.\ a compact 3D cluster of the same number of atoms?

    \item The Boys function $\Boys{n}(T)$ decreases with both $n$ and $T$. What are the physical reasons for each dependence?

    \item Why is the number of Rys roots $\lfloor L/2 \rfloor + 1$ rather than $L + 1$? What property of Gaussian quadrature enables this efficiency?
\end{enumerate}

\subsection{Extensions for Advanced Students}

\begin{enumerate}
    \item Implement downward recursion for the Boys function starting from the asymptotic formula. Compare stability with upward recursion across all $T$ regimes.

    \item Derive the relationship between the Boys function and the incomplete gamma function: $\Boys{n}(T) = \frac{1}{2T^{n+1/2}}\gamma(n+\tfrac{1}{2}, T)$.

    \item Implement a contracted $(ss|ss)$ ERI by summing over primitive pairs. Validate against PySCF for STO-3G hydrogen.

    \item Study the accuracy of Schwarz bounds: compute $|\eri{\mu}{\nu}{\lambda}{\sigma}|/(Q_{\mu\nu} Q_{\lambda\sigma})$ for various shell quartets. How tight is the bound?

    \item Implement the two-root Rys quadrature by solving the moment equations analytically. Verify that it exactly reproduces $\Boys{0}$, $\Boys{1}$, $\Boys{2}$, $\Boys{3}$.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{References}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{enumerate}
    \item Boys, S.F. (1950). ``Electronic wave functions. I. A general method of calculation for the stationary states of any molecular system.'' \textit{Proc. R. Soc. A} \textbf{200}, 542--554.

    \item Dupuis, M., Rys, J., and King, H.F. (1976). ``Evaluation of molecular integrals over Gaussian basis functions.'' \textit{J. Chem. Phys.} \textbf{65}, 111--116.

    \item H\"{a}ser, M. and Ahlrichs, R. (1989). ``Improvements on the direct SCF method.'' \textit{J. Comput. Chem.} \textbf{10}, 104--111. (Schwarz screening)

    \item Helgaker, T., J\o rgensen, P., and Olsen, J. (2000). \textit{Molecular Electronic-Structure Theory}. Wiley. Chapters 9--10.

    \item Szabo, A. and Ostlund, N.S. (1989). \textit{Modern Quantum Chemistry}. Dover Publications. Appendix A.

    \item Sun, Q. (2015). ``Libcint: An efficient general integral library for Gaussian basis functions.'' \textit{J. Comput. Chem.} \textbf{36}, 1664--1671.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exercise Answer Keys}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Brief answers for the end-of-chapter exercises (Section 4.10).

\vspace{0.5em}

%-------------------------------------------------------------------------------
\subsection{Exercise 4.1: Derive the $(ss|ss)$ Formula [Core]}

\begin{keyInsight}[Derivation Outline]
\textbf{(a) Apply GPT to bra and ket pairs:}

Starting from the primitive ERI:
\[
(ab|cd) = \iint \chi_a(\rvec_1)\chi_b(\rvec_1)\frac{1}{r_{12}}\chi_c(\rvec_2)\chi_d(\rvec_2)\,d\rvec_1\,d\rvec_2
\]

For the bra pair centered at $\mathbf{A}$ and $\mathbf{B}$ with exponents $\alpha$ and $\beta$:
\begin{align*}
\chi_a\chi_b &\propto e^{-\alpha|\rvec_1-\mathbf{A}|^2}e^{-\beta|\rvec_1-\mathbf{B}|^2} = e^{-p|\rvec_1-\mathbf{P}|^2}e^{-\mu R_{AB}^2}
\end{align*}
where $p = \alpha + \beta$, $\mu = \frac{\alpha\beta}{\alpha+\beta}$, and $\mathbf{P} = \frac{\alpha\mathbf{A}+\beta\mathbf{B}}{p}$.

Similarly for the ket pair:
\begin{align*}
\chi_c\chi_d &\propto e^{-q|\rvec_2-\mathbf{Q}|^2}e^{-\nu R_{CD}^2}
\end{align*}
where $q = \gamma + \delta$, $\nu = \frac{\gamma\delta}{\gamma+\delta}$, and $\mathbf{Q} = \frac{\gamma\mathbf{C}+\delta\mathbf{D}}{q}$.

\textbf{(b) Insert Gaussian representation of $1/r_{12}$:}

Using the integral identity:
\[
\frac{1}{r_{12}} = \frac{2}{\sqrt{\pi}}\int_0^\infty e^{-u^2 r_{12}^2}\,du
\]

The 6D spatial integral becomes:
\[
\int e^{-p|\rvec_1-\mathbf{P}|^2}\int e^{-q|\rvec_2-\mathbf{Q}|^2}\cdot e^{-u^2|\rvec_1-\rvec_2|^2}\,d\rvec_1\,d\rvec_2
\]

Using the Gaussian convolution formula, this evaluates to:
\[
\left(\frac{\pi^3}{(p+u^2)(q+u^2)(u^2 + \frac{pq}{p+q})}\right)^{1/2} \text{(simplified form)}
\]

After simplification, the spatial integrals yield:
\[
\frac{\pi^{5/2}}{pq\sqrt{p+q}}\,e^{-\rho|\mathbf{P}-\mathbf{Q}|^2 t^2} \quad\text{where } \rho = \frac{pq}{p+q}
\]

\textbf{(c) Transform to Boys function:}

The remaining $u$-integral has the form:
\[
\int_0^\infty f(u^2)\,du \to \int_0^1 t^0 e^{-Tt^2}\,dt = \Boys{0}(T)
\]
with substitution $t = u\sqrt{p+q}/\sqrt{pq}$ and $T = \rho R_{PQ}^2$.

\textbf{Final result:}
\[
(ab|cd) = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}\,e^{-\mu R_{AB}^2}\,e^{-\nu R_{CD}^2}\,\Boys{0}(T)
\]
(before normalization constants).
\end{keyInsight}

%-------------------------------------------------------------------------------
\subsection{Exercise 4.2: Limiting Behavior of ERIs [Core]}

\begin{keyInsight}[Analysis of Limits]
\textbf{(a) $R_{PQ} \to 0$ (coinciding pair centers):}

When $\mathbf{P} = \mathbf{Q}$:
\begin{itemize}
    \item $T = \rho R_{PQ}^2 = 0$
    \item $\Boys{0}(0) = \int_0^1 e^0\,dt = 1$
\end{itemize}

The ERI becomes:
\[
(ab|cd)\big|_{R_{PQ}=0} = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}\,e^{-\mu R_{AB}^2}\,e^{-\nu R_{CD}^2}
\]

The constant in terms of $p$ and $q$ is:
\[
\boxed{\frac{2\pi^{5/2}}{pq\sqrt{p+q}}}
\]

\textbf{(b) $R_{PQ} \to \infty$ (well-separated distributions):}

For large $T$: $\Boys{0}(T) \approx \frac{1}{2}\sqrt{\frac{\pi}{T}} = \frac{1}{2}\sqrt{\frac{\pi}{\rho R_{PQ}^2}}$

Substituting:
\begin{align*}
(ab|cd) &\approx \frac{2\pi^{5/2}}{pq\sqrt{p+q}} \cdot e^{-\mu R_{AB}^2} \cdot e^{-\nu R_{CD}^2} \cdot \frac{1}{2}\sqrt{\frac{\pi}{\rho}} \cdot \frac{1}{R_{PQ}}\\
&= \frac{\pi^3}{pq\sqrt{p+q}} \cdot \sqrt{\frac{p+q}{pq}} \cdot \frac{e^{-\mu R_{AB}^2}e^{-\nu R_{CD}^2}}{R_{PQ}}\\
&= \frac{\pi^3}{(pq)^{3/2}} \cdot \frac{e^{-\mu R_{AB}^2}e^{-\nu R_{CD}^2}}{R_{PQ}}
\end{align*}

\textbf{(c) Physical interpretation of $1/R_{PQ}$ decay:}

The $1/R_{PQ}$ decay is the \textbf{classical Coulomb law}:
\begin{itemize}
    \item At large separations, each overlap distribution $\chi_\mu\chi_\nu$ behaves like a localized charge centered at $\mathbf{P}$ or $\mathbf{Q}$.
    \item The interaction energy between two point charges at separation $R$ is $\propto 1/R$.
    \item The Gaussian prefactors $e^{-\mu R_{AB}^2}$ and $e^{-\nu R_{CD}^2}$ represent the ``compactness'' of each charge cloud.
    \item The ERI asymptotically matches the classical electrostatic picture, validating that quantum mechanics reproduces classical limits.
\end{itemize}
\end{keyInsight}

%-------------------------------------------------------------------------------
\subsection{Exercise 4.3: Schwarz Screening Experiment [Core]}

\textbf{Expected numerical results for \ce{H2O}:}

\begin{center}
\begin{tabular}{lccc}
\toprule
\textbf{Basis} & \textbf{NAO} & \textbf{$N^4$ (total)} & \textbf{Screened ($\tau=10^{-10}$)} \\
\midrule
STO-3G & 7 & 2,401 & 0--5\% \\
6-31G & 13 & 28,561 & 10--15\% \\
6-31+G* & 24 & 331,776 & 25--35\% \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Key observations:}
\begin{enumerate}
    \item The screened fraction \emph{increases} with diffuse functions because diffuse--diffuse pairs have small diagonal ERIs $(\mu\nu|\mu\nu)$ due to spatial spread.
    \item For compact bases (STO-3G), almost all ERIs are significant because basis functions overlap substantially.
    \item The Schwarz bound is guaranteed to be an upper bound: for 100 random quartets, no violation should occur (bound $\geq$ actual).
\end{enumerate}

\textbf{Implementation outline:}
\begin{lstlisting}
# Compute pair norms
Q = np.zeros((nao, nao))
for mu in range(nao):
    for nu in range(nao):
        Q[mu, nu] = np.sqrt(eri[mu, nu, mu, nu])

# Count screened ERIs
n_screened = 0
for mu, nu, lam, sig in product(range(nao), repeat=4):
    if Q[mu, nu] * Q[lam, sig] < tau:
        n_screened += 1
\end{lstlisting}

%-------------------------------------------------------------------------------
\subsection{Exercise 4.4: Boys Function Stability [Advanced]}

\textbf{Method comparison for $n \in \{0,\ldots,10\}$ and various $T$:}

\begin{center}
\begin{tabular}{lccc}
\toprule
$T$ & \textbf{Pure Upward} & \textbf{Hybrid Series/Rec} & \textbf{Downward} \\
\midrule
$10^{-10}$ & $10^{-3}$ (fails) & $10^{-15}$ & $10^{-15}$ \\
$10^{-6}$ & $10^{-5}$ (fails) & $10^{-15}$ & $10^{-15}$ \\
$10^{-2}$ & $10^{-8}$ (poor) & $10^{-15}$ & $10^{-15}$ \\
$1$ & $10^{-14}$ & $10^{-15}$ & $10^{-15}$ \\
$10$ & $10^{-14}$ & $10^{-14}$ & $10^{-15}$ \\
$100$ & $10^{-14}$ & $10^{-14}$ & $10^{-15}$ \\
\bottomrule
\end{tabular}
\end{center}
\vspace{0.5em}
\footnotesize{(Values show maximum absolute error vs.\ 128-point Gauss--Legendre reference)}
\normalsize

\textbf{Analysis:}
\begin{itemize}
    \item \textbf{Pure upward recursion} suffers catastrophic cancellation at small $T$ because $(2n+1)\Boys{n}(T) \approx e^{-T}$, leading to subtraction of nearly equal numbers.
    \item \textbf{Hybrid series/recursion} is robust: use series for $T < 25$ (converges rapidly), use erf + upward for $T \geq 25$ (no cancellation).
    \item \textbf{Downward recursion} is always stable because it involves \emph{addition}, not subtraction. Starting from a high $n_{\max}+5$ with the asymptotic formula and recursing down ``washes out'' initial errors.
\end{itemize}

\textbf{Recommendation:} Use hybrid series/recursion for simplicity, or downward recursion for maximum robustness.

%-------------------------------------------------------------------------------
\subsection{Exercise 4.5: Root Count Scaling with Angular Momentum [Conceptual]}

\textbf{Explanation (8--12 sentences):}

Higher angular momentum shells introduce polynomial factors $(x-A_x)^{\ell_A}(y-A_y)^{m_A}(z-A_z)^{n_A}$ into the ERI integrand, where $\ell_A + m_A + n_A = L_A$. When these polynomials are multiplied out across all four basis functions, the total polynomial degree in the Cartesian coordinates is $L = \ell_A + \ell_B + \ell_C + \ell_D$.

The derivative identity $\frac{d}{dT}\Boys{n}(T) = -\Boys{n+1}(T)$ shows that differentiating the $(ss|ss)$ formula with respect to center coordinates (to generate $p$-type integrals) brings in higher-order Boys functions. Specifically, each derivative effectively raises the Boys function order by one.

For a shell quartet with total angular momentum $L$, the ERI involves Boys functions $\Boys{0}(T), \Boys{1}(T), \ldots, \Boys{n_{\max}}(T)$ where $n_{\max} = \lfloor L/2 \rfloor$. The factor of 2 arises because the Rys substitution $x = t^2$ converts the Boys integral into a polynomial in $x$, doubling the effective polynomial degree that can be handled.

Gaussian quadrature with $n_r$ nodes exactly integrates polynomials up to degree $2n_r - 1$. Since we need to reproduce moments $x^0, x^1, \ldots, x^{n_{\max}}$, we require $n_{\max} \leq 2n_r - 1$, giving $n_r = \lceil (n_{\max}+1)/2 \rceil = \lfloor L/2 \rfloor + 1$.

The root count thus grows as $\lfloor L/2 \rfloor + 1$ rather than $L + 1$ because Gaussian quadrature is ``doubly efficient''---each root captures two polynomial degrees of freedom. This efficiency is fundamental to why Rys quadrature makes high-angular-momentum ERIs tractable.

%-------------------------------------------------------------------------------
\subsection{Exercise 4.6: ERI Symmetry Verification [Core]}

\textbf{Expected results for \ce{H2O}/STO-3G:}
\begin{itemize}
    \item Number of AOs: $N = 7$
    \item Total ERIs: $7^4 = 2401$
    \item Maximum symmetry deviation: $\sim 10^{-15}$ (machine precision)
\end{itemize}

\textbf{Symmetry relations to verify:}
\begin{enumerate}
    \item Bra swap: $(ij|kl) = (ji|kl)$
    \item Ket swap: $(ij|kl) = (ij|lk)$
    \item Bra-ket exchange: $(ij|kl) = (kl|ij)$
    \item All combinations (8 total permutations)
\end{enumerate}

\textbf{Implementation:}
\begin{lstlisting}
eri = mol.intor("int2e", aosym="s1")
max_dev = 0.0
for i in range(nao):
    for j in range(nao):
        for k in range(nao):
            for l in range(nao):
                ref = eri[i,j,k,l]
                # Check all 8 symmetry partners
                syms = [eri[j,i,k,l], eri[i,j,l,k], eri[j,i,l,k],
                        eri[k,l,i,j], eri[l,k,i,j], eri[k,l,j,i], eri[l,k,j,i]]
                for s in syms:
                    max_dev = max(max_dev, abs(ref - s))
print(f"Max deviation: {max_dev:.2e}")  # Should be ~1e-15
\end{lstlisting}

%-------------------------------------------------------------------------------
\subsection{Exercise 4.7: ERI Scaling with Basis Size [Core]}

\textbf{Expected results for water clusters in 6-31G:}

\begin{center}
\begin{tabular}{lcccc}
\toprule
\textbf{System} & $N$ & \textbf{Unique ERIs} & \textbf{Memory (s1)} & \textbf{Memory (s8)} \\
\midrule
\ce{H2O} & 13 & 9,316 & 0.23 MB & 0.07 MB \\
\ce{(H2O)2} & 26 & 136,526 & 3.7 MB & 1.1 MB \\
\ce{(H2O)3} & 39 & 630,630 & 18.5 MB & 5.0 MB \\
\ce{(H2O)4} & 52 & 1,936,771 & 58.7 MB & 15.5 MB \\
\ce{(H2O)5} & 65 & 4,691,115 & 143 MB & 37.5 MB \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Scaling analysis:}
\begin{itemize}
    \item Full tensor: $N^4 \times 8$ bytes (s1 format)
    \item Symmetric storage: $\frac{N(N+1)}{2}\cdot\frac{N(N+1)/2+1}{2} \times 8$ bytes (s8 format)
    \item Memory becomes prohibitive ($>1$ GB) around $N \approx 100$ for s1, $N \approx 180$ for s8.
\end{itemize}

The $\bigO{N^4}$ scaling is confirmed by plotting $\log(\text{ERIs})$ vs $\log(N)$: slope $\approx 4$.

%-------------------------------------------------------------------------------
\subsection{Exercise 4.8: Moment Matching for Rys Quadrature [Advanced]}

\textbf{(a) Moments at $T = 1.0$:}
\begin{center}
\begin{tabular}{cc}
\toprule
$k$ & $m_k(1.0) = 2\Boys{k}(1.0)$ \\
\midrule
0 & 1.4936 \\
1 & 0.5213 \\
2 & 0.2614 \\
3 & 0.1555 \\
4 & 0.1027 \\
5 & 0.0727 \\
\bottomrule
\end{tabular}
\end{center}

\textbf{(b) One-root quadrature ($n_r = 1$):}
\[
W_1 = m_0 = 1.4936, \quad x_1 = \frac{m_1}{m_0} = \frac{0.5213}{1.4936} = 0.349
\]

Verification:
\begin{itemize}
    \item $W_1 \cdot x_1^0 = 1.4936 = m_0$ \checkmark
    \item $W_1 \cdot x_1^1 = 0.5213 = m_1$ \checkmark
    \item $W_1 \cdot x_1^2 = 0.182 \neq m_2 = 0.261$ (not exact for $k \geq 2$)
\end{itemize}

\textbf{(c) Two-root quadrature ($n_r = 2$):}

Using Hankel matrix construction:
\[
\mat{H} = \begin{pmatrix} m_0 & m_1 \\ m_1 & m_2 \end{pmatrix}, \quad
\mat{H}^{(1)} = \begin{pmatrix} m_1 & m_2 \\ m_2 & m_3 \end{pmatrix}
\]

After Cholesky factorization and eigenvalue solution:
\begin{align*}
x_1 &\approx 0.116, \quad W_1 \approx 0.651 \\
x_2 &\approx 0.619, \quad W_2 \approx 0.843
\end{align*}

Verification: $\sum_i W_i x_i^k = m_k$ exactly for $k = 0, 1, 2, 3$.

\textbf{(d) Quadrature error pattern:}

For $n_r$ roots, moments are reproduced exactly up to order $2n_r - 1$, then errors appear:
\begin{center}
\begin{tabular}{cccc}
\toprule
$k$ & $n_r = 1$ error & $n_r = 2$ error & $n_r = 3$ error \\
\midrule
0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 \\
2 & $7.9 \times 10^{-2}$ & 0 & 0 \\
3 & $9.4 \times 10^{-2}$ & 0 & 0 \\
4 & -- & $8.2 \times 10^{-3}$ & 0 \\
5 & -- & $1.4 \times 10^{-2}$ & 0 \\
\bottomrule
\end{tabular}
\end{center}

The pattern confirms: $n_r$ points give exact moments for $k = 0, 1, \ldots, 2n_r - 1$.

%-------------------------------------------------------------------------------
\subsection{Exercise 4.9: Boys Function Evaluation Strategies [Research/Challenge]}

\textbf{Comparative analysis:}

\begin{center}
\begin{tabular}{lccc}
\toprule
\textbf{Method} & \textbf{Accuracy} & \textbf{Speed} & \textbf{Memory} \\
\midrule
Tabulation + interpolation & $10^{-10}$ & Fast & $\sim$50 KB \\
Chebyshev approximation & $10^{-12}$ & Fastest & $\sim$5 KB \\
Rational (Pad\'{e}) approximation & $10^{-14}$ & Fast & $\sim$2 KB \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Strategy details:}

\textbf{(a) Tabulation + interpolation:}
\begin{itemize}
    \item Grid spacing $\Delta T = 0.1$ for $T \in [0, 30]$, plus asymptotic for $T > 30$
    \item Cubic spline gives $\sim 10^{-10}$ accuracy with 300 table entries per $n$
    \item Total memory: $11 \times 300 \times 8$ bytes $\approx$ 26 KB for $n \leq 10$
\end{itemize}

\textbf{(b) Chebyshev approximation:}
\begin{itemize}
    \item Divide $T$ range: $[0,2]$, $[2,10]$, $[10,30]$, plus asymptotic
    \item 12--15 Chebyshev terms per range achieve $10^{-12}$ accuracy
    \item Very fast evaluation via Clenshaw recurrence
\end{itemize}

\textbf{(c) Rational (Pad\'{e}) approximation:}
\begin{itemize}
    \item libcint uses rational function fits in different $T$ regimes
    \item $(5,5)$ or $(6,6)$ Pad\'{e} approximants suffice for $10^{-14}$ accuracy
    \item Minimal memory footprint; efficient for vectorized evaluation
\end{itemize}

\textbf{Discussion:}

Production codes (libcint, GAMESS, Gaussian) typically use:
\begin{itemize}
    \item Series expansion for $T < T_{\text{switch}}$ ($T_{\text{switch}} \approx 15$--$30$)
    \item Asymptotic + downward recursion for large $T$
    \item Precomputed tables or polynomial fits for intermediate $T$ to avoid function calls
\end{itemize}

The trade-off is between accuracy, speed, and code complexity. For educational purposes, the series + recursion hybrid is simplest; for production, Chebyshev or rational fits offer the best speed/accuracy balance.

\end{document}
