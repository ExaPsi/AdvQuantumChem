%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ch05_solutions.tex
% Answer Key for Chapter 5: Rys Quadrature in Practice
%
% Course: 2302638 Advanced Quantum Chemistry
% Institution: Department of Chemistry, Faculty of Science, Chulalongkorn University
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{../../solutions_style}

\title{\textbf{Chapter 5: Answer Key}\\
\large Rys Quadrature in Practice\\
\normalsize 2302638 Advanced Quantum Chemistry}
\author{Department of Chemistry, Chulalongkorn University}
\date{}

\begin{document}
\maketitle
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Overview}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This answer key covers:
\begin{itemize}
    \item \textbf{14 Checkpoint Questions} embedded throughout Chapter 5, testing conceptual understanding
    \item \textbf{4 Python Labs} (5A, 5B, 5C, 5D) with expected numerical results and validation criteria
\end{itemize}

\noindent\textbf{Key concepts tested:}
\begin{enumerate}
    \item Boys functions as moments of a weight function
    \item Gaussian quadrature construction via Hankel matrices
    \item The Golub--Welsch algorithm for nodes/weights
    \item Root count rule for ERIs
    \item Derivative identity for angular momentum
    \item Coulomb and exchange matrix construction
\end{enumerate}

\noindent\textbf{Validation standard:} All numerical results should match PySCF reference calculations to within the specified tolerances (typically $< 10^{-10}$).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Checkpoint Question Answers}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This section provides detailed answers to all 14 checkpoint questions from Chapter 5,
organized by their location in the chapter.

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.1: Orthonormalization Revisited (Section 5.1)}
\label{sec:cp51}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.1 -- Gram--Schmidt Parallel]
\textbf{Question:} In Chapter~2 we orthonormalized a function space with Gram--Schmidt/eigendecomposition,
using the overlap matrix $\Smat$ as the Gram matrix.
In this chapter we orthonormalize a \emph{polynomial} space (with a weight $w_T(x)$) to obtain
Gaussian quadrature nodes and weights.
The linear algebra is the same; only the objects change.
Which matrix in Algorithm~5.1 plays the role of the overlap matrix $\Smat$?
\textit{(Hint: It encodes the inner products $\langle x^i, x^j \rangle_w$.)}

\textbf{Answer:}

\textbf{The Hankel matrix $\mat{H}$ plays the role of the overlap matrix $\Smat$.}

\textbf{Detailed explanation:}

In Chapter~2, the overlap matrix $\Smat$ is defined by:
\[
S_{\mu\nu} = \langle \chi_\mu | \chi_\nu \rangle = \int \chi_\mu(\mathbf{r}) \chi_\nu(\mathbf{r})\, d\mathbf{r}
\]
It is the Gram matrix of AO basis functions under the standard $L^2$ inner product.

In Chapter~5, we work with monomials $\{1, x, x^2, \ldots, x^{n_r-1}\}$ and a weighted inner product:
\[
\langle f, g \rangle_T = \int_0^1 f(x)\, g(x)\, w_T(x)\, dx
\]
where $w_T(x) = x^{-1/2} e^{-Tx}$.

The Gram matrix of monomials under this inner product is:
\[
H_{ij} = \langle x^i, x^j \rangle_T = \int_0^1 x^{i+j}\, w_T(x)\, dx = m_{i+j}(T)
\]

This is precisely the Hankel matrix $\mat{H}$ from Eq.~(5.12).

\textbf{The parallel structure:}
\begin{center}
\begin{tabular}{lcc}
\toprule
 & Chapter 2 (AOs) & Chapter 5 (Polynomials) \\
\midrule
Basis elements & $\chi_\mu$ (GTOs) & $x^k$ (monomials) \\
Inner product & $\langle \chi_\mu | \chi_\nu \rangle$ & $\langle x^i, x^j \rangle_T$ \\
Gram matrix & $\Smat$ & $\mat{H}$ (Hankel) \\
Orthonormalization & $\Smat = \mat{U}\mathbf{s}\mat{U}\T$ & $\mat{H} = \mat{L}\mat{L}\T$ (Cholesky) \\
Result & Orthonormal AOs & Orthonormal polynomials \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Why Cholesky works like Gram--Schmidt:}

The Cholesky factorization $\mat{H} = \mat{L}\mat{L}\T$ and the transformation $\mat{C} = \mat{L}^{-1}$ gives:
\[
\mat{C}\mat{H}\mat{C}\T = \mat{L}^{-1}\mat{L}\mat{L}\T\mat{L}^{-\top} = \mat{I}
\]

This means the rows of $\mat{C}$ define coefficients for orthonormal polynomials in the monomial basis---exactly analogous to how the canonical orthogonalizer $\Xmat = \mat{U}\mathbf{s}^{-1/2}$ transforms AOs into orthonormal combinations.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.2: One Root Suffices for Two Boys Values (Section 5.2)}
\label{sec:cp52}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.2 -- Moment Matching]
\textbf{Question:} For $n_r=1$, Eq.~(5.8) is exact for polynomial degrees $0$ and $1$.
\begin{enumerate}[label=(\alph*), noitemsep]
  \item Write out the moment-matching equations for $n=0$ and $n=1$ explicitly.
  \item Show that one root suffices to reproduce both $\Boys{0}(T)$ and $\Boys{1}(T)$.
  \item What are $x_1$ and $W_1$ in terms of $m_0$ and $m_1$?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Moment-matching equations:}

For $n_r = 1$, we have a single node $x_1$ and weight $W_1$. The moment-matching conditions (Eq.~5.8) state:
\[
m_n = \sum_{i=1}^{n_r} W_i x_i^n = W_1 x_1^n
\]
must hold for $n = 0, 1, \ldots, 2n_r - 1 = 1$.

Explicitly:
\begin{align}
n = 0: \quad & m_0 = W_1 x_1^0 = W_1 \\
n = 1: \quad & m_1 = W_1 x_1^1 = W_1 x_1
\end{align}

\textbf{(b) One root reproduces $\Boys{0}$ and $\Boys{1}$:}

From the moment definition $m_n = 2\Boys{n}(T)$:
\begin{align}
\Boys{0}(T) &= \frac{m_0}{2} = \frac{W_1}{2} \\
\Boys{1}(T) &= \frac{m_1}{2} = \frac{W_1 x_1}{2}
\end{align}

These are exact because the quadrature with $n_r = 1$ point is exact for polynomials of degree $\le 2(1) - 1 = 1$.

\textbf{(c) Solving for $x_1$ and $W_1$:}

From the moment-matching equations:
\begin{align}
W_1 &= m_0 \\
W_1 x_1 &= m_1
\end{align}

Dividing the second by the first:
\[
\boxed{x_1 = \frac{m_1}{m_0} = \frac{2\Boys{1}(T)}{2\Boys{0}(T)} = \frac{\Boys{1}(T)}{\Boys{0}(T)}}
\]
\[
\boxed{W_1 = m_0 = 2\Boys{0}(T)}
\]

\textbf{Numerical verification for $T = 1.0$:}
\begin{itemize}
    \item $\Boys{0}(1.0) = 0.5\sqrt{\pi/1.0} \cdot \mathrm{erf}(1.0) \approx 0.7468$
    \item $\Boys{1}(1.0) = \frac{(2\cdot 0 + 1)\Boys{0}(1.0) - e^{-1.0}}{2\cdot 1.0} \approx 0.1894$
    \item $x_1 = 0.1894/0.7468 \approx 0.2536$
    \item $W_1 = 2 \times 0.7468 \approx 1.4936$
\end{itemize}

These match the expected values in Exercise 5.1.
\end{checkpointAnswer}

\begin{keyformulabox}
For one-root Rys quadrature:
\[
x_1 = \frac{\Boys{1}(T)}{\Boys{0}(T)}, \qquad W_1 = 2\Boys{0}(T)
\]
\end{keyformulabox}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.2b: Interpreting the Rys Weight Figure (Section 5.2)}
\label{sec:cp52b}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.2 -- Weight Function Behavior]
\textbf{Question:} Examine Figure~5.1.
\begin{enumerate}[label=(\alph*), noitemsep]
  \item As $T$ increases, the weight function becomes more sharply peaked near $x = 0$.
        What happens to the quadrature nodes? Why does this make physical sense?
        \textit{(Hint: Large $T$ corresponds to widely separated centers in the ERI.)}
  \item The total area under $w_T(x)$ equals $m_0(T) = 2\Boys{0}(T)$. For larger $T$,
        is this area larger or smaller? Relate this to the asymptotic behavior
        $\Boys{0}(T) \to \tfrac{1}{2}\sqrt{\pi/T}$ for $T \to \infty$.
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Node clustering behavior:}

As $T$ increases, the quadrature nodes $\{x_i\}$ cluster toward $x = 0$.

\textbf{Why this happens:}
The weight function $w_T(x) = x^{-1/2} e^{-Tx}$ has two factors:
\begin{itemize}
    \item $x^{-1/2}$: Singular at $x = 0$, always pulls nodes toward small $x$
    \item $e^{-Tx}$: Decay factor that becomes steeper as $T$ increases
\end{itemize}

For large $T$, the exponential decay dominates: $w_T(x)$ drops off rapidly for $x > 1/T$. The weight is effectively concentrated in a small region near $x = 0$, so optimal quadrature nodes (which sample where the weight is largest) must cluster there.

\textbf{Physical interpretation:}
Large $T = \rho |\mathbf{P} - \mathbf{Q}|^2$ corresponds to widely separated electron distributions (bra pair at $\mathbf{P}$, ket pair at $\mathbf{Q}$). At large separation:
\begin{itemize}
    \item The Coulomb interaction $1/r_{12}$ becomes weaker and nearly classical
    \item The quantum exchange effects (represented by the polynomial factors) become negligible
    \item The integral is dominated by the asymptotic regime of the Boys function
\end{itemize}

The node clustering toward $x = 0$ reflects this physics: at large separation, only the ``soft'' part of the Coulomb interaction matters.

\textbf{(b) Total area (zeroth moment) behavior:}

For larger $T$, the total area $m_0(T) = 2\Boys{0}(T)$ is \textbf{smaller}.

\textbf{Quantitative behavior:}
\begin{itemize}
    \item $T = 0$: $m_0(0) = 2\Boys{0}(0) = 2 \cdot 1 = 2$
    \item $T = 1$: $m_0(1) = 2\Boys{0}(1) \approx 2 \times 0.747 \approx 1.49$
    \item $T = 10$: $m_0(10) = 2\Boys{0}(10) \approx 2 \times 0.158 \approx 0.32$
    \item $T \to \infty$: $m_0(T) \to 2 \cdot \frac{1}{2}\sqrt{\frac{\pi}{T}} = \sqrt{\frac{\pi}{T}} \to 0$
\end{itemize}

\textbf{Physical meaning:}
The decreasing area reflects the decreasing Coulomb interaction strength at large separation. The asymptotic form $\Boys{0}(T) \sim \sqrt{\pi/(4T)}$ gives the classical Coulomb law: the integral of $e^{-Tr^2}/r$ over all space scales as $1/\sqrt{T} \propto 1/R_{PQ}$, consistent with the $1/r$ distance dependence.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.3: Weight Positivity (Section 5.3)}
\label{sec:cp53}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.3 -- Golub--Welsch]
\textbf{Question:} Why must all $W_i$ be positive for a positive weight $w_T(x)$?
Use Eq.~(5.15) and the fact that $m_0 > 0$.

\textbf{Answer:}

\textbf{The Golub--Welsch weight formula:}

From Eq.~(5.15), the quadrature weights are:
\[
W_i = m_0 (V_{0i})^2
\]
where $V_{0i}$ is the first component of the $i$-th normalized eigenvector of the Jacobi matrix $\mat{J}$.

\textbf{Why $W_i > 0$:}

\begin{enumerate}
    \item \textbf{$m_0 > 0$:} The zeroth moment is
    \[
    m_0 = \int_0^1 w_T(x)\, dx = \int_0^1 x^{-1/2} e^{-Tx}\, dx > 0
    \]
    because the integrand is strictly positive on $(0, 1]$.

    \item \textbf{$(V_{0i})^2 \ge 0$:} Any real number squared is non-negative.

    \item \textbf{$(V_{0i})^2 > 0$:} For Gaussian quadrature derived from orthogonal polynomials with a positive weight function, the eigenvectors of the Jacobi matrix are such that $V_{0i} \neq 0$ for all $i$.
\end{enumerate}

\textbf{Physical interpretation:}

The positivity of weights is a fundamental property of Gaussian quadrature for positive weights. If any weight were negative, the quadrature could not be interpreted as an expectation value:
\[
\int_0^1 f(x) w_T(x)\, dx \approx \sum_i W_i f(x_i)
\]
A negative $W_i$ would allow the approximation to be negative even when $f(x) \ge 0$ everywhere, which would be inconsistent with the integral being manifestly non-negative.

\textbf{Connection to probability:}

The normalized weights $\tilde{W}_i = W_i / m_0$ satisfy $\sum_i \tilde{W}_i = 1$ and $\tilde{W}_i > 0$---they form a discrete probability distribution. The quadrature nodes are the ``sample points'' for this distribution.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.4: Eigenvalue Interpretation (Section 5.3)}
\label{sec:cp54}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.3 -- Jacobi Matrix Properties]
\textbf{Question:} The nodes $x_i$ are eigenvalues of the Jacobi matrix $\mat{J}$.
\begin{enumerate}[label=(\alph*), noitemsep]
  \item What property of $\mat{J}$ guarantees that all $x_i$ are real?
  \item Why must $x_i \in (0,1)$ for the Rys weight $w_T(x) = x^{-1/2}e^{-Tx}$?
        \textit{(Hint: The roots of orthogonal polynomials lie in the interior of the weight's support.)}
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Reality of eigenvalues:}

The Jacobi matrix $\mat{J}$ is \textbf{real symmetric}:
\[
J_{kk} = a_k, \quad J_{k,k+1} = J_{k+1,k} = b_{k+1}
\]
where the recurrence coefficients $a_k$ and $b_k$ are real.

By the spectral theorem for symmetric matrices: \emph{all eigenvalues of a real symmetric matrix are real.}

Additionally, the eigenvectors are orthogonal and can be chosen to be real. This guarantees that the quadrature nodes $\{x_i\}$ are real numbers.

\textbf{(b) Why $x_i \in (0, 1)$:}

This follows from a fundamental theorem in orthogonal polynomial theory:

\textbf{Theorem:} \textit{The zeros of the $n$-th orthogonal polynomial $p_n(x)$ with respect to a positive weight function $w(x)$ on interval $(a, b)$ are all real, simple, and lie strictly inside $(a, b)$.}

For Rys quadrature:
\begin{itemize}
    \item The weight is $w_T(x) = x^{-1/2} e^{-Tx}$
    \item The support is $(0, 1)$
    \item The quadrature nodes are the zeros of $p_{n_r}(x)$
\end{itemize}

Therefore, all nodes satisfy $0 < x_i < 1$.

\textbf{Physical intuition:}

The quadrature nodes are the ``optimal sampling points'' for the weight function. Since $w_T(x)$ is nonzero only on $(0, 1)$, placing nodes outside this interval would waste sampling effort on regions where the weight is zero. The optimal placement is in the interior where the weight is most significant.

\textbf{Note on the singularity at $x = 0$:}

The weight $w_T(x) = x^{-1/2} e^{-Tx}$ has an integrable singularity at $x = 0$ (since $\int_0^1 x^{-1/2}\, dx = 2$ is finite). This singularity causes the moments and hence the quadrature to be ``pulled'' toward small $x$ values, especially when $T$ is large. However, all nodes remain strictly positive: $x_i > 0$.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.5: Algorithm 5.1 Understanding (Section 5.4)}
\label{sec:cp55}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.4 -- Algorithm 5.1]
\textbf{Question:}
\begin{enumerate}[label=(\alph*), noitemsep]
  \item Why do we need moments up to $m_{2n_r-1}$ in Algorithm~5.1?
        \textit{(Hint: What is the largest index required in $\mat{H}$ and $\mat{H}^{(1)}$?)}
  \item What happens if the Cholesky factorization fails in step~3?
        \textit{(Hint: Think about the condition number of $\mat{H}$.)}
  \item Why is the Jacobi matrix $\mat{J}$ guaranteed to be symmetric?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Why moments up to $m_{2n_r-1}$:}

The Hankel matrix $\mat{H}$ has entries:
\[
H_{ij} = m_{i+j}, \quad i, j = 0, 1, \ldots, n_r - 1
\]

The largest index occurs at $i = j = n_r - 1$:
\[
H_{n_r-1, n_r-1} = m_{2(n_r-1)} = m_{2n_r - 2}
\]

The shifted Hankel matrix $\mat{H}^{(1)}$ has entries:
\[
H^{(1)}_{ij} = m_{i+j+1}, \quad i, j = 0, 1, \ldots, n_r - 1
\]

The largest index is:
\[
H^{(1)}_{n_r-1, n_r-1} = m_{2n_r - 2 + 1} = m_{2n_r - 1}
\]

Therefore, we need \textbf{all moments from $m_0$ to $m_{2n_r-1}$}.

\textbf{Example for $n_r = 2$:}
\[
\mat{H} = \begin{pmatrix} m_0 & m_1 \\ m_1 & m_2 \end{pmatrix}, \quad
\mat{H}^{(1)} = \begin{pmatrix} m_1 & m_2 \\ m_2 & m_3 \end{pmatrix}
\]
Requires $m_0, m_1, m_2, m_3$ (i.e., $2 \times 2 - 1 = 3$ is the highest index).

\textbf{(b) What if Cholesky fails:}

Cholesky factorization requires the matrix to be \textbf{positive definite}. For well-behaved moments, $\mat{H}$ should be positive definite because it is the Gram matrix of linearly independent monomials.

Failure can occur when:
\begin{enumerate}
    \item The moments are computed inaccurately (especially for extreme $T$)
    \item $n_r$ is too large, causing $\mat{H}$ to become ill-conditioned
    \item Numerical rounding causes near-zero or negative pivots
\end{enumerate}

The condition number $\kappa(\mat{H})$ grows rapidly with $n_r$:
\begin{center}
\begin{tabular}{lc}
\toprule
$n_r$ & Typical $\kappa(\mat{H})$ at $T = 1$ \\
\midrule
2 & $\sim 10^2$ \\
3 & $\sim 10^4$ \\
4 & $\sim 10^6$ \\
5 & $\sim 10^8$ \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Practical remedy:} Production codes use specialized root-finding algorithms (polynomial approximations, extended precision) rather than the moment-based approach for large $n_r$.

\textbf{(c) Why $\mat{J}$ is symmetric:}

The Jacobi matrix is constructed as:
\[
\mat{J} = \mat{C} \mat{H}^{(1)} \mat{C}\T
\]
where $\mat{C} = \mat{L}^{-1}$ is lower triangular.

Since $\mat{H}^{(1)}$ is a Hankel matrix, it is symmetric ($H^{(1)}_{ij} = m_{i+j+1} = H^{(1)}_{ji}$).

For any symmetric matrix $\mat{A}$ and any matrix $\mat{C}$:
\[
(\mat{C}\mat{A}\mat{C}\T)\T = (\mat{C}\T)\T \mat{A}\T \mat{C}\T = \mat{C}\mat{A}\mat{C}\T
\]
Therefore, $\mat{J} = \mat{C}\mat{H}^{(1)}\mat{C}\T$ is symmetric.

\textbf{Alternative view:} The Jacobi matrix represents ``multiply by $x$'' in the orthonormal polynomial basis. Since $x$ is real and the inner product is symmetric, this operator is self-adjoint, guaranteeing a symmetric matrix representation.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.6: Root Count Understanding (Section 5.5)}
\label{sec:cp56}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.5 -- Root Count Rule]
\textbf{Question:}
\begin{enumerate}[label=(\alph*), noitemsep]
  \item Use Eq.~(5.19) to verify the root counts in Table~5.1.
  \item Explain why $\eri{s}{s}{s}{s}$ requires $n_r = 1$ even though
        $L = 0$. \textit{(Hint: What is the minimum polynomial degree
        that must be integrated exactly?)}
  \item What would happen if you used $n_r = 1$ for a $\eri{p}{p}{p}{p}$
        integral? Which Boys functions would be incorrect?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Verifying root counts:}

The formula is $n_r = \lfloor L/2 \rfloor + 1$ where $L = \ell_A + \ell_B + \ell_C + \ell_D$:

\begin{center}
\begin{tabular}{lcccc}
\toprule
Shell quartet & $\ell_A + \ell_B + \ell_C + \ell_D$ & $L$ & $\lfloor L/2 \rfloor + 1$ & $n_r$ \\
\midrule
$\eri{s}{s}{s}{s}$ & $0+0+0+0$ & 0 & $0+1$ & 1 \\
$\eri{p}{s}{s}{s}$ & $1+0+0+0$ & 1 & $0+1$ & 1 \\
$\eri{p}{p}{s}{s}$ & $1+1+0+0$ & 2 & $1+1$ & 2 \\
$\eri{p}{p}{p}{p}$ & $1+1+1+1$ & 4 & $2+1$ & 3 \\
$\eri{d}{d}{p}{p}$ & $2+2+1+1$ & 6 & $3+1$ & 4 \\
$\eri{f}{f}{f}{f}$ & $3+3+3+3$ & 12 & $6+1$ & 7 \\
\bottomrule
\end{tabular}
\end{center}

\textbf{(b) Why $(ss|ss)$ requires $n_r = 1$:}

Even though $L = 0$, we still need to integrate at least degree-0 polynomials (constants) exactly. The quadrature must satisfy:
\[
m_0 = \int_0^1 x^0 \cdot w_T(x)\, dx = W_1
\]

With $n_r = 0$ (no nodes), we could not represent any integral at all. The formula gives:
\[
n_r = \lfloor 0/2 \rfloor + 1 = 0 + 1 = 1
\]

One root is the minimum needed to reproduce the zeroth moment $m_0 = 2\Boys{0}(T)$.

\textbf{Physical interpretation:} Even for $s$-functions, the electron repulsion integral involves the Boys function $\Boys{0}(T)$. This requires at least one quadrature point to evaluate.

\textbf{(c) Using $n_r = 1$ for $(pppp)$:}

For $\eri{p}{p}{p}{p}$, $L = 4$, so we need $n_r = 3$.

With only $n_r = 1$, the quadrature is exact for polynomials of degree $\le 2(1) - 1 = 1$.

We can compute:
\begin{itemize}
    \item $\Boys{0}(T) = \frac{1}{2}W_1$ \textbf{(correct)}
    \item $\Boys{1}(T) = \frac{1}{2}W_1 x_1$ \textbf{(correct)}
    \item $\Boys{2}(T) = \frac{1}{2}W_1 x_1^2$ \textbf{(INCORRECT)}
    \item $\Boys{3}(T) = \frac{1}{2}W_1 x_1^3$ \textbf{(INCORRECT)}
    \item $\Boys{4}(T) = \frac{1}{2}W_1 x_1^4$ \textbf{(INCORRECT)}
\end{itemize}

The ERI for $(pppp)$ requires Boys functions through $\Boys{4}$. With $n_r = 1$, $\Boys{2}, \Boys{3}, \Boys{4}$ would all be computed incorrectly, leading to wrong integral values.

The errors can be substantial. For example, at $T = 1.0$:
\begin{itemize}
    \item $\Boys{2}(1.0)_{\text{exact}} \approx 0.0818$
    \item $\Boys{2}(1.0)_{\text{1-point}} = \frac{1}{2}W_1 x_1^2 \approx 0.048$ (error $\sim 40\%$)
\end{itemize}
\end{checkpointAnswer}

\begin{warningbox}
Using insufficient Rys roots is a silent error---the code runs but produces wrong answers. Always verify root counts match the angular momentum of your shell quartet.
\end{warningbox}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.6b: Resolving the Circularity (Section 5.6)}
\label{sec:cp56b}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.6 -- Why Rys Quadrature?]
\textbf{Question:}
\begin{enumerate}[label=(\alph*), noitemsep]
  \item Explain in your own words why the ``circularity'' in Rys quadrature
        is actually not circular for integrals with $L > 0$.
  \item For a $(pp|pp)$ shell quartet ($L = 4$), how many Rys roots are needed?
        How many individual Cartesian integrals share these same nodes and weights?
  \item If someone proposed using 10-point Gauss--Legendre quadrature instead
        of Rys quadrature for ERI evaluation, what would be wrong with this approach?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Why the apparent circularity is not circular for $L > 0$:}

The apparent circularity is: ``We compute Boys functions to get Rys nodes/weights, then use those to compute Boys functions.'' This seems pointless---but it misses the key distinction between \textbf{scalar values} and \textbf{structured integrands}.

\textbf{For $(ss|ss)$ ($L = 0$):} The integral is simply a prefactor times $\Boys{0}(T)$. Direct Boys evaluation is all you need. The Rys machinery is unnecessary (though it works as a validation test).

\textbf{For $L > 0$:} The integrand has the form
\[
\int_0^1 P(t) \cdot w_T(t^2)\, dt
\]
where $P(t) = I_x(t) \cdot I_y(t) \cdot I_z(t)$ is a polynomial of degree up to $L$ that encodes the angular momentum structure and depends on the specific Cartesian component being computed.

This polynomial \textbf{cannot} be factored out of the integral. You must evaluate $P(t)$ at specific quadrature points $t_i = \sqrt{x_i}$ and sum:
\[
\text{ERI} = \sum_{i=1}^{n_r} W_i \cdot P(t_i)
\]

The ``circularity'' breaks because:
\begin{enumerate}
    \item We compute scalar Boys values $\Boys{n}(T)$ to build the quadrature \textbf{once per shell quartet}
    \item We then evaluate \textbf{many different polynomials} $P(t)$ at the quadrature nodes
    \item The polynomial $P(t)$ varies for each Cartesian component; the nodes/weights do not
\end{enumerate}

The Rys quadrature transforms the problem from ``evaluate complicated integrals'' to ``evaluate simple polynomials at known points and sum.''

\textbf{(b) $(pp|pp)$ analysis:}

\textbf{Root count:}
\[
L = \ell_A + \ell_B + \ell_C + \ell_D = 1 + 1 + 1 + 1 = 4
\]
\[
n_r = \lfloor L/2 \rfloor + 1 = \lfloor 4/2 \rfloor + 1 = 2 + 1 = 3
\]

So $(pp|pp)$ requires \textbf{3 Rys roots}.

\textbf{Number of Cartesian integrals:}
Each $p$-shell has 3 Cartesian components: $p_x$, $p_y$, $p_z$.
\[
\text{Total integrals} = 3 \times 3 \times 3 \times 3 = 81
\]

\textbf{Amortization:} The 3 Rys nodes and 3 weights (computed once from moments $m_0, m_1, \ldots, m_5$) are shared by all 81 integrals. The expensive Boys function calls are amortized over a large batch.

\textbf{(c) Why Gauss--Legendre would be wrong:}

Gauss--Legendre quadrature is designed for the weight function $w(x) = 1$ on $[-1, 1]$. Using it for ERI evaluation has two fatal problems:

\textbf{Problem 1: Wrong weight function.}
The Rys weight is $w_T(x) = x^{-1/2} e^{-Tx}$, not $w(x) = 1$. Gauss--Legendre nodes and weights do not account for this weight. The quadrature formula
\[
\int_0^1 f(x) \cdot w_T(x)\, dx \approx \sum_{i=1}^n W_i^{GL} f(x_i^{GL})
\]
is simply wrong---it would compute $\int f(x)\, dx$, not $\int f(x) w_T(x)\, dx$.

\textbf{Problem 2: Inefficiency.}
Even if you included $w_T(x)$ in the integrand (i.e., computed $\int f(x) w_T(x)\, dx$ using GL quadrature on $f(x) w_T(x)$), you would lose the exactness property. Gauss--Legendre is exact for polynomials, but $P(x) \cdot w_T(x)$ is not a polynomial (it has the $x^{-1/2} e^{-Tx}$ factor). You would need many more GL points to achieve the same accuracy that Rys quadrature achieves exactly with $n_r$ points.

\textbf{The key insight:} Rys quadrature is Gaussian quadrature \textbf{for the specific weight function} $w_T(x)$. This makes it exact for polynomial integrands of the form $P(x) \cdot w_T(x)$ with minimal points. Using any other quadrature rule (Gauss--Legendre, Simpson's, etc.) would either give wrong answers or require vastly more points.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.7: Method Equivalence (Section 5.7 -- ERIs via Boys and Rys)}
\label{sec:cp57}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.6 -- Validation Strategy]
\textbf{Question:}
\begin{enumerate}[label=(\alph*), noitemsep]
  \item Why does the Rys formula $\Boys{0}(T) = \tfrac{1}{2}\sum_i W_i$ not depend on
        the nodes $x_i$?
  \item Under what conditions might direct $\Boys{0}$ evaluation be preferable to
        Rys quadrature? \textit{(Hint: Consider computational cost for a single
        isolated ERI versus a batch of ERIs sharing the same $T$.)}
  \item If your Rys implementation has a sign error in the Cholesky factorization,
        would this $(ss|ss)$ test catch it? Why or why not?
\end{enumerate}

\textbf{Answer:}

\textbf{(a) Why $\Boys{0}$ is node-independent:}

The general formula is:
\[
\Boys{n}(T) = \frac{1}{2} \sum_{i=1}^{n_r} W_i x_i^n
\]

For $n = 0$:
\[
\Boys{0}(T) = \frac{1}{2} \sum_{i=1}^{n_r} W_i x_i^0 = \frac{1}{2} \sum_{i=1}^{n_r} W_i
\]

Since $x_i^0 = 1$ for any $x_i$, the nodes cancel out. Only the sum of weights matters.

\textbf{Mathematical interpretation:} $\Boys{0}(T)$ is half the zeroth moment $m_0 = 2\Boys{0}(T) = \sum_i W_i$, which by construction is preserved exactly regardless of where the nodes are placed.

\textbf{(b) When direct Boys evaluation is preferable:}

\textbf{Direct evaluation is better when:}
\begin{itemize}
    \item Computing a single isolated ERI (setup cost of Rys quadrature not amortized)
    \item Only $\Boys{0}$ is needed (no benefit from reproducing higher moments)
    \item $T$ is very small or very large (extreme regimes where Rys construction can be unstable)
\end{itemize}

\textbf{Rys quadrature is better when:}
\begin{itemize}
    \item Many ERIs share the same $T$ value (construct nodes/weights once, reuse)
    \item Multiple Boys orders are needed (get $\Boys{0}, \ldots, \Boys{2n_r-1}$ from one construction)
    \item Integrating in the full Rys framework (nodes serve double duty in ERI recurrences)
\end{itemize}

\textbf{(c) Would a sign error be caught by $(ss|ss)$?}

\textbf{Probably not.} Here's why:

A sign error in Cholesky might produce $\mat{L}$ with wrong signs in off-diagonal elements. However:
\begin{itemize}
    \item For $n_r = 1$, $\mat{H}$ is $1 \times 1$: $\mat{H} = (m_0)$, so $L = \sqrt{m_0}$
    \item There are no off-diagonal elements to get wrong
    \item The weight $W_1 = m_0 (V_{01})^2$ involves a square, so sign errors in $V_{01}$ don't matter
\end{itemize}

A more robust test would use $n_r \ge 2$, where the Hankel matrix has off-diagonal elements and sign errors in the Cholesky factor would propagate to incorrect nodes and weights.

\textbf{Recommendation:} Test with $n_r = 2$ and verify all four moments $m_0, m_1, m_2, m_3$ to properly validate the implementation.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.8: Identifying Derivative Sources (Section 5.8)}
\label{sec:cp58}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.7 -- Derivative Identity]
\textbf{Question:} In the derivation of Eq.~(5.28), which term comes from differentiating the Gaussian prefactor
$\exp[-\mu R_{AB}^2]$, and which term comes from differentiating the Boys function?

\textbf{Answer:}

The $(p_\xi s|ss)$ formula (Eq.~5.28) is:
\[
(p_\xi b|cd) = \frac{2\pi^{5/2}}{pq\sqrt{p+q}} e^{-\mu R_{AB}^2} e^{-\nu R_{CD}^2}
\left[ -\frac{\beta}{p}(A_\xi - B_\xi)\Boys{0}(T) - \frac{\rho}{p}(P_\xi - Q_\xi)\Boys{1}(T) \right]
\]

\textbf{Term 1: From differentiating the Gaussian prefactor}
\[
\boxed{-\frac{\beta}{p}(A_\xi - B_\xi)\Boys{0}(T)}
\]

This comes from:
\[
\frac{\partial}{\partial A_\xi}\left(-\mu R_{AB}^2\right) = -2\mu(A_\xi - B_\xi)
\]

When combined with the $1/(2\alpha)$ from the derivative identity and using $\mu/\alpha = \beta/p$, we get the factor $-(\beta/p)(A_\xi - B_\xi)$.

The Boys function remains $\Boys{0}(T)$ because this differentiation acts on the exponential, not on the Boys function.

\textbf{Term 2: From differentiating the Boys function}
\[
\boxed{-\frac{\rho}{p}(P_\xi - Q_\xi)\Boys{1}(T)}
\]

This comes from applying the chain rule to $\Boys{0}(T)$ where $T = \rho|\mathbf{P} - \mathbf{Q}|^2$:
\[
\frac{\partial}{\partial A_\xi}\Boys{0}(T) = \frac{d\Boys{0}}{dT}\frac{\partial T}{\partial A_\xi} = -\Boys{1}(T) \cdot 2\rho(P_\xi - Q_\xi)\frac{\alpha}{p}
\]

using the Boys derivative identity $d\Boys{0}/dT = -\Boys{1}(T)$.

\textbf{Physical interpretation:}
\begin{itemize}
    \item The $\Boys{0}$ term: Accounts for the shift in the ``bra'' pair center due to the $p$-function's angular factor
    \item The $\Boys{1}$ term: Accounts for the change in Coulomb interaction distance as the angular momentum shifts probability density
\end{itemize}
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.9: Structure of the $(ps|ss)$ Formula (Section 5.8)}
\label{sec:cp59}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.7 -- $(ps|ss)$ Formula]
\textbf{Question:} Equation~(5.28) contains two terms with different geometric factors.
One involves $(A_\xi - B_\xi)$, the other involves $(P_\xi - Q_\xi)$.
What happens to each term when $\mathbf{A} = \mathbf{B}$ (i.e., both functions on the same center)?
What physical situation does this represent?

\textbf{Answer:}

\textbf{When $\mathbf{A} = \mathbf{B}$:}

If the bra functions are on the same center, then:
\begin{itemize}
    \item $A_\xi - B_\xi = 0$ for all $\xi$
    \item $\mathbf{P} = (\alpha\mathbf{A} + \beta\mathbf{B})/p = \mathbf{A}$ (composite center coincides with both centers)
\end{itemize}

The formula simplifies to:
\[
(p_\xi s|ss) = \frac{2\pi^{5/2}}{pq\sqrt{p+q}} e^{-\nu R_{CD}^2}
\left[ 0 - \frac{\rho}{p}(A_\xi - Q_\xi)\Boys{1}(T) \right]
\]

Only the $\Boys{1}$ term survives! The $\Boys{0}$ term vanishes entirely.

\textbf{Physical interpretation:}

This represents an ERI where both the $p$ and $s$ functions are centered on the same atom (say, a $2p$ and $1s$ on the same atom).

The first term, proportional to $(A_\xi - B_\xi)$, represents the ``two-center Gaussian product'' contribution. When both functions are on the same center, there is no separation and this contribution vanishes.

The second term, proportional to $(P_\xi - Q_\xi) = (A_\xi - Q_\xi)$, represents the electron-electron interaction between the bra pair (at $\mathbf{A}$) and the ket pair (at $\mathbf{Q}$). This remains nonzero as long as the ket functions are on different centers from the bra functions.

\textbf{Special case: Four-center collapse}

If additionally $\mathbf{C} = \mathbf{D} = \mathbf{A}$ (all functions on the same atom), then $\mathbf{Q} = \mathbf{A}$, so $(A_\xi - Q_\xi) = 0$ as well.

For certain symmetry components (like $p_x$ when the molecule is symmetric about the $x$-axis), the integral may vanish entirely. This is used in integral screening based on symmetry.
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.10: Crossed Indices in Exchange (Section 5.9)}
\label{sec:cp510}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.8 -- J and K Contractions]
\textbf{Question:} In Eq.~(5.35), why are the indices ``crossed'' compared to Eq.~(5.34)?
Relate this to the structure of exchange (fermionic antisymmetry).

\textbf{Answer:}

The contractions are:
\begin{align}
\text{Coulomb:} \quad J_{\mu\nu} &= \sum_{\lambda\sigma} \eri{\mu}{\nu}{\lambda}{\sigma} P_{\lambda\sigma} \\
\text{Exchange:} \quad K_{\mu\nu} &= \sum_{\lambda\sigma} \eri{\mu}{\lambda}{\nu}{\sigma} P_{\lambda\sigma}
\end{align}

\textbf{Physical origin of the crossing:}

The Coulomb and exchange integrals arise from expanding $\langle\Psi|\hat{V}_{ee}|\Psi\rangle$ where $\Psi$ is a Slater determinant.

For a two-electron system with orbitals $\phi_i$ and $\phi_j$, the determinant gives:
\[
\Psi(1,2) = \frac{1}{\sqrt{2}}[\phi_i(1)\phi_j(2) - \phi_j(1)\phi_i(2)]
\]

Computing $\langle\Psi|\frac{1}{r_{12}}|\Psi\rangle$:
\begin{align}
\langle\Psi|\frac{1}{r_{12}}|\Psi\rangle &= \frac{1}{2}\left[ \langle\phi_i\phi_j|\phi_i\phi_j\rangle + \langle\phi_j\phi_i|\phi_j\phi_i\rangle \right. \\
&\quad \left. - \langle\phi_i\phi_j|\phi_j\phi_i\rangle - \langle\phi_j\phi_i|\phi_i\phi_j\rangle \right]
\end{align}

The first two terms (Coulomb-type) have the same orbital on each electron before and after the operator:
\[
\text{Coulomb:} \quad \langle\phi_i(1)\phi_j(2)|\frac{1}{r_{12}}|\phi_i(1)\phi_j(2)\rangle = (ii|jj)
\]

The last two terms (Exchange-type) have orbitals swapped:
\[
\text{Exchange:} \quad \langle\phi_i(1)\phi_j(2)|\frac{1}{r_{12}}|\phi_j(1)\phi_i(2)\rangle = (ij|ji)
\]

\textbf{In the AO basis:}

Expanding MOs in AOs: $\phi_i = \sum_\mu C_{\mu i}\chi_\mu$

The Coulomb contribution becomes:
\[
\sum_{\mu\nu\lambda\sigma} C_{\mu i}C_{\nu i}^* \eri{\mu}{\nu}{\lambda}{\sigma} C_{\lambda j}C_{\sigma j}^* \propto \eri{\mu}{\nu}{\lambda}{\sigma}
\]

The Exchange contribution has the swap:
\[
\sum_{\mu\nu\lambda\sigma} C_{\mu i}C_{\lambda i}^* \eri{\mu}{\lambda}{\nu}{\sigma} C_{\nu j}C_{\sigma j}^* \propto \eri{\mu}{\lambda}{\nu}{\sigma}
\]

The $\lambda$ and $\nu$ indices are swapped in the second bra position and first ket position---this is the ``crossing'' visible in the exchange formula.

\textbf{Summary:}
\begin{center}
\begin{tabular}{lll}
\toprule
 & Coulomb & Exchange \\
\midrule
ERI index pattern & $(\mu\nu|\lambda\sigma)$ & $(\mu\lambda|\nu\sigma)$ \\
Physical meaning & Classical repulsion & Fermionic exchange \\
Sign in Fock matrix & $+1$ & $-\frac{1}{2}$ (RHF) \\
\bottomrule
\end{tabular}
\end{center}
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.11: Symmetry of J and K (Section 5.9)}
\label{sec:cp511}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.8 -- Matrix Symmetry]
\textbf{Question:} Both $\Jmat$ and $\Kmat$ inherit symmetry from the ERIs and density matrix.
Using the 8-fold ERI symmetry and the fact that $\mat{P}$ is symmetric for real orbitals,
show that $J_{\mu\nu} = J_{\nu\mu}$ and $K_{\mu\nu} = K_{\nu\mu}$.

\textbf{Answer:}

\textbf{8-fold ERI symmetry (real basis):}
\begin{align}
\eri{\mu}{\nu}{\lambda}{\sigma} &= \eri{\nu}{\mu}{\lambda}{\sigma} = \eri{\mu}{\nu}{\sigma}{\lambda} = \eri{\nu}{\mu}{\sigma}{\lambda} \\
&= \eri{\lambda}{\sigma}{\mu}{\nu} = \eri{\sigma}{\lambda}{\mu}{\nu} = \eri{\lambda}{\sigma}{\nu}{\mu} = \eri{\sigma}{\lambda}{\nu}{\mu}
\end{align}

Key symmetries we'll use:
\begin{itemize}
    \item $\eri{\mu}{\nu}{\lambda}{\sigma} = \eri{\nu}{\mu}{\lambda}{\sigma}$ (swap first pair)
    \item $\eri{\mu}{\nu}{\lambda}{\sigma} = \eri{\lambda}{\sigma}{\mu}{\nu}$ (swap bra and ket)
    \item $\eri{\mu}{\lambda}{\nu}{\sigma} = \eri{\nu}{\sigma}{\mu}{\lambda}$ (combined)
\end{itemize}

\textbf{Proof that $J_{\mu\nu} = J_{\nu\mu}$:}
\begin{align}
J_{\mu\nu} &= \sum_{\lambda\sigma} \eri{\mu}{\nu}{\lambda}{\sigma} P_{\lambda\sigma} \\
&= \sum_{\lambda\sigma} \eri{\nu}{\mu}{\lambda}{\sigma} P_{\lambda\sigma} \quad \text{(swap first pair)} \\
&= J_{\nu\mu}
\end{align}

\textbf{Proof that $K_{\mu\nu} = K_{\nu\mu}$:}

This requires more care due to the crossed index structure:
\begin{align}
K_{\mu\nu} &= \sum_{\lambda\sigma} \eri{\mu}{\lambda}{\nu}{\sigma} P_{\lambda\sigma}
\end{align}

Using the symmetry $\eri{\mu}{\lambda}{\nu}{\sigma} = \eri{\nu}{\sigma}{\mu}{\lambda}$:
\begin{align}
K_{\mu\nu} &= \sum_{\lambda\sigma} \eri{\nu}{\sigma}{\mu}{\lambda} P_{\lambda\sigma}
\end{align}

Relabeling dummy indices $\lambda \leftrightarrow \sigma$:
\begin{align}
K_{\mu\nu} &= \sum_{\sigma\lambda} \eri{\nu}{\lambda}{\mu}{\sigma} P_{\sigma\lambda}
\end{align}

Using $P_{\sigma\lambda} = P_{\lambda\sigma}$ (symmetry of density matrix):
\begin{align}
K_{\mu\nu} &= \sum_{\lambda\sigma} \eri{\nu}{\lambda}{\mu}{\sigma} P_{\lambda\sigma} = K_{\nu\mu}
\end{align}

\textbf{Consequence:}

Both $\Jmat$ and $\Kmat$ are symmetric matrices. Therefore:
\begin{itemize}
    \item The Fock matrix $\Fmat = \Hcore + \Jmat - \frac{1}{2}\Kmat$ is symmetric
    \item We only need to compute half the matrix elements (upper or lower triangle)
    \item The Roothaan-Hall equations have real eigenvalues
\end{itemize}
\end{checkpointAnswer}

%-------------------------------------------------------------------------------
\subsection{Checkpoint 5.12: Why $\mat{V}_{HF}$ Rather Than Separate $\Jmat$ and $\Kmat$ (Section 5.10)}
\label{sec:cp512}
%-------------------------------------------------------------------------------

\begin{checkpointAnswer}[Section 5.9 -- Validation Approach]
\textbf{Question:} Why is it meaningful to compare $\mat{V}_{HF}=\Jmat-\tfrac{1}{2}\Kmat$ rather than
$\Jmat$ and $\Kmat$ separately when validating an RHF implementation?

\textbf{Answer:}

\textbf{Physical reason:}

The quantity that enters the Fock matrix and determines physical observables is always the combination:
\[
\mat{G} = \Jmat - \frac{1}{2}\Kmat = \mat{V}_{HF}
\]

Individual $\Jmat$ and $\Kmat$ matrices depend on implementation details (how ERIs are stored, symmetry conventions, etc.), but their combination is unambiguous.

\textbf{Practical reasons:}

\begin{enumerate}
    \item \textbf{Convention differences:} Some codes define $K$ with a factor of 2 already included, or use different index conventions. The Fock matrix $\Fmat = \Hcore + \Jmat - \frac{1}{2}\Kmat$ is invariant to these conventions.

    \item \textbf{Numerical stability:} For some density matrices, $\Jmat$ and $\Kmat$ individually might have large elements that partially cancel. Comparing them separately could show spurious differences that cancel in the physically meaningful combination.

    \item \textbf{Algorithmic variations:} Different integral engines may compute $\Jmat - \frac{1}{2}\Kmat$ directly (especially with density fitting) rather than computing $\Jmat$ and $\Kmat$ separately. Validating against the combined quantity allows flexibility in implementation.

    \item \textbf{Error propagation:} A sign error in $\Kmat$ (a common mistake) would show up as a factor-of-2 error in $\mat{G}$, making it easy to diagnose. If validating $\Jmat$ and $\Kmat$ separately, you might mistakenly think your $\Kmat$ is ``just a factor of 2 off'' when actually the physics would be completely wrong.
\end{enumerate}

\textbf{Energy validation:}

The electronic energy:
\[
E_{\text{elec}} = \tr{\Pmat\Hcore} + \frac{1}{2}\tr{\Pmat(\Jmat - \frac{1}{2}\Kmat)} = \tr{\Pmat\Hcore} + \frac{1}{2}\tr{\Pmat\mat{G}}
\]

Again, only the combination $\mat{G}$ appears, not $\Jmat$ or $\Kmat$ individually.

\textbf{Bottom line:} Validate against physically meaningful quantities. For RHF, that means $\mat{G}$, total energy, and MO eigenvalues---not intermediate quantities whose definitions may vary.
\end{checkpointAnswer}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Lab Solutions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-------------------------------------------------------------------------------
\subsection{Lab 5A: Construct Rys Nodes/Weights and Verify Moment Matching}
%-------------------------------------------------------------------------------

\begin{solutionbox}[Lab 5A Objectives]
\begin{itemize}
    \item Implement Algorithm 5.1 (Hankel + Cholesky + Golub-Welsch)
    \item Verify moment matching for $n = 0, 1, \ldots, 2n_r - 1$
    \item Test across a range of $T$ values
\end{itemize}
\end{solutionbox}

\textbf{Expected numerical results for $n_r = 2$:}

\begin{center}
\begin{tabular}{lcccc}
\toprule
$T$ & $x_1$ & $x_2$ & $W_1$ & $W_2$ \\
\midrule
0.0 & 0.1156 & 0.7416 & 1.3043 & 0.6957 \\
0.1 & 0.1133 & 0.7373 & 1.2802 & 0.6551 \\
1.0 & 0.0955 & 0.6956 & 1.0999 & 0.3938 \\
10.0 & 0.0274 & 0.2711 & 0.5086 & 0.0519 \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Moment matching errors:}

For properly implemented code, all moment-matching errors should be $< 10^{-12}$:

\begin{outputbox}
\begin{verbatim}
T = 0.0, nroots = 2
  n= 0: m_exact=2.000000000000e+00  m_quad=2.000000000000e+00  diff=+0.000e+00
  n= 1: m_exact=6.666666666667e-01  m_quad=6.666666666667e-01  diff=-1.110e-16
  n= 2: m_exact=4.000000000000e-01  m_quad=4.000000000000e-01  diff=+5.551e-17
  n= 3: m_exact=2.857142857143e-01  m_quad=2.857142857143e-01  diff=-5.551e-17

T = 1.0, nroots = 2
  n= 0: m_exact=1.493648265624e+00  m_quad=1.493648265624e+00  diff=+2.220e-16
  n= 1: m_exact=3.788393107578e-01  m_quad=3.788393107578e-01  diff=+5.551e-17
  n= 2: m_exact=1.636351336279e-01  m_quad=1.636351336279e-01  diff=-2.776e-17
  n= 3: m_exact=9.078568549346e-02  m_quad=9.078568549346e-02  diff=-1.388e-17

T = 10.0, nroots = 2
  n= 0: m_exact=3.158296978397e-01  m_quad=3.158296978397e-01  diff=+5.551e-17
  n= 1: m_exact=3.452149952927e-02  m_quad=3.452149952927e-02  diff=+6.939e-18
  n= 2: m_exact=8.160693108665e-03  m_quad=8.160693108665e-03  diff=+8.674e-19
  n= 3: m_exact=2.686600954609e-03  m_quad=2.686600954609e-03  diff=-1.084e-19
\end{verbatim}
\end{outputbox}

\textbf{Key observations:}
\begin{enumerate}
    \item All moments $m_0, m_1, m_2, m_3$ are reproduced to machine precision ($\sim 10^{-15}$)
    \item The construction is stable across a wide range of $T$ (from 0 to 10+)
    \item Nodes cluster toward smaller $x$ as $T$ increases (weight function peaks near $x=0$)
    \item All nodes lie in $(0, 1)$ as required
    \item All weights are positive
\end{enumerate}

\textbf{Validation criteria:}
\begin{center}
\begin{tabular}{lc}
\toprule
Check & Tolerance \\
\midrule
$|m_n^{\text{quad}} - m_n^{\text{exact}}|$ & $< 10^{-12}$ \\
All $x_i \in (0, 1)$ & Exact \\
All $W_i > 0$ & Exact \\
$\sum_i W_i = m_0$ & $< 10^{-14}$ \\
\bottomrule
\end{tabular}
\end{center}

\begin{warningbox}[Common Implementation Errors]
\begin{enumerate}
    \item \textbf{Wrong moment count:} Using $m_0, \ldots, m_{n_r-1}$ instead of $m_0, \ldots, m_{2n_r-1}$
    \item \textbf{Hankel indexing:} Off-by-one errors in $H_{ij} = m_{i+j}$ vs $m_{i+j-1}$
    \item \textbf{Forgetting symmetrization:} The Jacobi matrix may have tiny asymmetry due to rounding; symmetrize before eigendecomposition
    \item \textbf{Boys function accuracy:} Using only the series or only the recurrence; need both for full $T$ range
\end{enumerate}
\end{warningbox}

%-------------------------------------------------------------------------------
\subsection{Lab 5B: Compute $(ss|ss)$ ERI Using Rys Quadrature}
%-------------------------------------------------------------------------------

\begin{solutionbox}[Lab 5B Objectives]
\begin{itemize}
    \item Use Rys quadrature to evaluate $\Boys{0}(T)$
    \item Compute a normalized $(ss|ss)$ ERI
    \item Validate against PySCF \texttt{int2e}
\end{itemize}
\end{solutionbox}

\textbf{Test case:}
\begin{itemize}
    \item Molecule: Two H atoms along $z$-axis, $R = 1.4$ Bohr
    \item Exponents: $\alpha = 0.5$, $\beta = 0.4$
    \item Computing: $\eri{a}{a}{b}{b}$ where $a$ is on atom 1, $b$ is on atom 2
\end{itemize}

\textbf{Expected numerical results:}

\begin{outputbox}
\begin{verbatim}
(aa|bb) PySCF = 0.31009149920742376
(aa|bb) Rys   = 0.3100914992074238
difference    = 1.1102230246251565e-16
\end{verbatim}
\end{outputbox}

\textbf{Intermediate values for verification:}
\begin{center}
\begin{tabular}{lc}
\toprule
Quantity & Value \\
\midrule
$p = \alpha + \beta$ & 0.9 \\
$q = \gamma + \delta$ (same as $p$ for this test) & 0.9 \\
$\mu = \alpha\beta/p$ & 0.222... \\
$\rho = pq/(p+q)$ & 0.45 \\
$R_{PQ} = |\mathbf{P} - \mathbf{Q}| = 1.4$ & 1.4 Bohr \\
$T = \rho \cdot R_{PQ}^2$ & 0.882 \\
$\Boys{0}(T)$ & 0.7937... \\
Prefactor $\frac{2\pi^{5/2}}{pq\sqrt{p+q}}$ & 40.89... \\
Gaussian prefactors & $e^{0} \cdot e^{-\nu R_{CD}^2}$ \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Validation criteria:}
\begin{center}
\begin{tabular}{lc}
\toprule
Check & Tolerance \\
\midrule
$|\text{ERI}_{\text{Rys}} - \text{ERI}_{\text{PySCF}}|$ & $< 10^{-12}$ \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Key code verification:}
\begin{lstlisting}
# The key formula
pref = 2 * (math.pi**2.5) / (p*q*math.sqrt(p+q))
F0 = 0.5 * float(np.sum(W))  # Rys quadrature for F_0
val_unnorm = pref * math.exp(-mu*Rab2 - nu*Rcd2) * F0
val_norm = Ns(alpha)*Ns(beta)*Ns(gamma)*Ns(delta)*val_unnorm
\end{lstlisting}

%-------------------------------------------------------------------------------
\subsection{Lab 5C: Compute $(p_\xi s|ss)$ Using Derivative Identity}
%-------------------------------------------------------------------------------

\begin{solutionbox}[Lab 5C Objectives]
\begin{itemize}
    \item Implement Eq.~(5.28) for $(p_\xi s|ss)$ ERIs
    \item Use Rys quadrature for both $\Boys{0}(T)$ and $\Boys{1}(T)$
    \item Validate against PySCF for multiple axis choices
\end{itemize}
\end{solutionbox}

\textbf{Test case:}
\begin{itemize}
    \item Molecule: Two H atoms along $z$-axis, $R = 1.4$ Bohr
    \item Atom 1 (A): $p$-shell with exponent $\alpha = 0.5$
    \item Atom 2 (B): $s$-shell with exponent $\beta = 0.4$
    \item Computing: $(p_z@1, s@2 | s@2, s@2)$
\end{itemize}

\textbf{Expected numerical results:}

\begin{outputbox}
\begin{verbatim}
AO labels:
0 0 H@1 px
1 0 H@1 py
2 0 H@1 pz
3 1 H@2 s

(p_z s|ss) PySCF = -0.04584115117181389
(p_z s|ss) Rys   = -0.04584115117181389
difference        = 0.0

(p_x s|ss) PySCF = 0.0
(p_x s|ss) Rys   = 0.0
difference        = 0.0
\end{verbatim}
\end{outputbox}

\textbf{Key observations:}
\begin{enumerate}
    \item $p_z$ integral is nonzero because atoms are separated along $z$
    \item $p_x$ and $p_y$ integrals are zero by symmetry (perpendicular to bond axis)
    \item The $\Boys{1}$ term contributes meaningfully---this is the first case where nodes matter
\end{enumerate}

\textbf{Formula verification:}

The unnormalized formula is:
\[
(p_\xi b|cd) = \frac{2\pi^{5/2}}{pq\sqrt{p+q}} e^{-\mu R_{AB}^2} e^{-\nu R_{CD}^2}
\left[ -\frac{\beta}{p}(A_\xi - B_\xi)\Boys{0}(T) - \frac{\rho}{p}(P_\xi - Q_\xi)\Boys{1}(T) \right]
\]

For our test case with atoms at $(0,0,0)$ and $(0,0,1.4)$:
\begin{itemize}
    \item $A_z - B_z = 0 - 1.4 = -1.4$
    \item $P_z = \alpha \cdot 0 / p = 0$ (since A is at origin)
    \item $Q_z = (\beta \cdot 1.4 + \beta \cdot 1.4)/(2\beta) = 1.4$
    \item $P_z - Q_z = 0 - 1.4 = -1.4$
\end{itemize}

Both terms contribute with the same sign, giving a negative integral value.

\textbf{Validation criteria:}
\begin{center}
\begin{tabular}{lc}
\toprule
Check & Tolerance \\
\midrule
$|\text{ERI}_{\text{Rys}} - \text{ERI}_{\text{PySCF}}|$ (nonzero cases) & $< 10^{-10}$ \\
$|\text{ERI}|$ for symmetry-zero cases & $< 10^{-14}$ \\
\bottomrule
\end{tabular}
\end{center}

%-------------------------------------------------------------------------------
\subsection{Lab 5D: Build $\Jmat$ and $\Kmat$ from ERIs}
%-------------------------------------------------------------------------------

\begin{solutionbox}[Lab 5D Objectives]
\begin{itemize}
    \item Implement J and K matrix construction via \texttt{einsum}
    \item Validate against PySCF \texttt{get\_jk}
    \item Verify energy reconstruction
\end{itemize}
\end{solutionbox}

\textbf{Test system:} \ce{H2O} / STO-3G
\begin{itemize}
    \item Geometry: O at origin, H at $(\pm 0.7586, 0, 0.5043)$ Angstrom
    \item Basis: STO-3G (7 AOs)
    \item Use converged SCF density from PySCF
\end{itemize}

\textbf{Expected numerical results:}

\begin{outputbox}
\begin{verbatim}
||J - J_ref||_F = 1.2432e-14
||K - K_ref||_F = 8.9547e-15
||VHF - VHF_ref||_F = 1.1025e-14

Energy reconstruction check:
  E_elec (from integrals) = -84.58939189
  E_elec (from PySCF)     = -84.58939189
  Difference              = 0.00e+00 Hartree

  E_nuc = 9.64350679
  E_tot = -74.94588510 Hartree
  PySCF E_tot = -74.94588510 Hartree
\end{verbatim}
\end{outputbox}

\textbf{Key formulas verified:}
\begin{lstlisting}
# J and K contractions
J = np.einsum("ijkl,kl->ij", eri, P, optimize=True)
K = np.einsum("ikjl,kl->ij", eri, P, optimize=True)

# Two-electron Fock contribution
VHF = J - 0.5 * K

# Energy reconstruction
h = T + V  # Core Hamiltonian
E_elec = np.einsum('ij,ji->', P, h) + 0.5 * np.einsum('ij,ji->', P, VHF)
E_tot = E_elec + mol.energy_nuc()
\end{lstlisting}

\textbf{Validation criteria:}
\begin{center}
\begin{tabular}{lc}
\toprule
Check & Tolerance \\
\midrule
$\|\Jmat - \Jmat_{\text{ref}}\|_F$ & $< 10^{-12}$ \\
$\|\Kmat - \Kmat_{\text{ref}}\|_F$ & $< 10^{-12}$ \\
$\|\mat{V}_{HF} - \mat{V}_{HF,\text{ref}}\|_F$ & $< 10^{-12}$ \\
$|E_{\text{tot}} - E_{\text{tot,PySCF}}|$ & $< 10^{-10}$ Hartree \\
\bottomrule
\end{tabular}
\end{center}

\begin{warningbox}[Common Student Errors in Lab 5D]
\begin{enumerate}
    \item \textbf{Wrong einsum indices for K:}
    \begin{lstlisting}
# WRONG:
K = np.einsum("ijkl,jk->il", eri, P)  # This is NOT the exchange!

# CORRECT:
K = np.einsum("ikjl,kl->ij", eri, P)
    \end{lstlisting}
    The exchange has a ``crossed'' index structure.

    \item \textbf{Missing factor of 1/2 in energy:}
    \begin{lstlisting}
# WRONG:
E_elec = np.trace(P @ h) + np.trace(P @ VHF)

# CORRECT:
E_elec = np.trace(P @ h) + 0.5 * np.trace(P @ VHF)
    \end{lstlisting}
    The two-electron term is counted twice in the Fock matrix approach.

    \item \textbf{Confusing Frobenius norm with element-wise comparison:}
    $\|\Jmat - \Jmat_{\text{ref}}\|_F$ can be small even if some elements differ more than others.
    For debugging, also check $\max|J_{ij} - J_{ij}^{\text{ref}}|$.
\end{enumerate}
\end{warningbox}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Additional Notes for Instructors}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Common Misconceptions}

\begin{enumerate}
    \item \textbf{``Rys quadrature is just another numerical integration method'':}
    Unlike Simpson's rule or Gauss-Legendre, Rys quadrature is \emph{exact} for the polynomial degrees it targets. For ERIs, this means no numerical integration error---only floating-point precision limits accuracy.

    \item \textbf{``More roots is always better'':}
    Using more roots than necessary is wasteful and can introduce numerical instability (ill-conditioned Hankel matrix). Use exactly $n_r = \lfloor L/2 \rfloor + 1$.

    \item \textbf{``The nodes don't matter for $(ss|ss)$'':}
    While true that only $\Boys{0}$ is needed and only weights appear in the formula, this is the exception. For any higher angular momentum, nodes are essential.

    \item \textbf{``Coulomb and exchange are just different ways of summing ERIs'':}
    They represent fundamentally different physics: classical electrostatics vs. quantum mechanical exchange arising from fermionic antisymmetry.
\end{enumerate}

\subsection{Suggested Discussion Questions}

\begin{enumerate}
    \item Why does libcint use specialized polynomial approximations for Rys roots rather than the moment-based Algorithm 5.1?

    \item How would you modify the $(p_\xi s|ss)$ derivation to get $(p_\xi p_\eta|ss)$? What additional Boys functions appear?

    \item The exchange matrix $\Kmat$ is more expensive to compute than $\Jmat$ in direct SCF. Why? (Hint: Consider how the contraction indices relate to shell-pair screening.)

    \item What happens to Rys quadrature accuracy when $T \to 0$ or $T \to \infty$?
\end{enumerate}

\subsection{Extensions for Advanced Students}

\begin{enumerate}
    \item Implement the $(pp|ss)$ ERI using double differentiation and validate against PySCF.

    \item Study the Hankel matrix condition number as a function of $n_r$ and $T$. At what point does the algorithm become unstable?

    \item Compare the Rys quadrature approach to Obara-Saika recurrence relations for a simple case.

    \item Implement Schwarz screening and measure how many ERIs can be skipped for \ce{H2O} in various basis sets.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{References}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{enumerate}
    \item Dupuis, M., Rys, J., \& King, H.F. (1976). ``Evaluation of molecular integrals over Gaussian basis functions.'' \textit{J. Chem. Phys.} \textbf{65}, 111--116.

    \item Rys, J., Dupuis, M., \& King, H.F. (1983). ``Computation of electron repulsion integrals using the Rys quadrature method.'' \textit{J. Comput. Chem.} \textbf{4}, 154--157.

    \item Golub, G.H. \& Welsch, J.H. (1969). ``Calculation of Gauss quadrature rules.'' \textit{Math. Comp.} \textbf{23}, 221--230.

    \item Szabo, A. \& Ostlund, N.S. (1989). \textit{Modern Quantum Chemistry}. Dover Publications. Appendix A.

    \item Sun, Q. (2015). ``Libcint: An efficient general integral library for Gaussian basis functions.'' \textit{J. Comput. Chem.} \textbf{36}, 1664--1671.
\end{enumerate}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exercise Answer Keys}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Brief answers for the end-of-chapter exercises (Section 5.12).

%-------------------------------------------------------------------------------
\subsection{Exercise 5.1: One-Root Quadrature Formulas [Core]}

\begin{keyInsight}[One-Root Derivation]
For $n_r = 1$, we have one node $x_1$ and one weight $W_1$. The moment-matching conditions state:
\begin{align}
n = 0: \quad m_0 &= W_1 x_1^0 = W_1 \\
n = 1: \quad m_1 &= W_1 x_1^1 = W_1 x_1
\end{align}

Solving these simultaneously:
\[
\boxed{W_1 = m_0 = 2\Boys{0}(T)}, \qquad \boxed{x_1 = \frac{m_1}{m_0} = \frac{\Boys{1}(T)}{\Boys{0}(T)}}
\]
\end{keyInsight}

\textbf{Numerical Verification:}

\begin{center}
\begin{tabular}{lcccc}
\toprule
$T$ & $\Boys{0}(T)$ & $\Boys{1}(T)$ & $x_1$ & $W_1$ \\
\midrule
0.01 & 0.9900 & 0.3267 & 0.3300 & 1.980 \\
0.1 & 0.9538 & 0.3040 & 0.3187 & 1.908 \\
1.0 & 0.7468 & 0.1894 & 0.2536 & 1.494 \\
10.0 & 0.1579 & 0.0173 & 0.1095 & 0.316 \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Validation:}
\begin{itemize}
    \item For $T = 1.0$: $x_1 \approx 0.254$, $W_1 \approx 1.494$ (matches expected values)
    \item Moment-matching errors: $|W_1 \cdot 1 - m_0| < 10^{-15}$, $|W_1 x_1 - m_1| < 10^{-15}$
    \item Both moments reproduced to machine precision
\end{itemize}

%-------------------------------------------------------------------------------
\subsection{Exercise 5.2: Two-Root Quadrature and Moment Matching [Core]}

\begin{keyInsight}[Algorithm 5.1 for $n_r = 2$]
For two-root quadrature, we need moments $m_0, m_1, m_2, m_3$ (i.e., $2n_r - 1 = 3$).

\textbf{Step 1: Hankel matrices}
\[
\mat{H} = \begin{pmatrix} m_0 & m_1 \\ m_1 & m_2 \end{pmatrix}, \quad
\mat{H}^{(1)} = \begin{pmatrix} m_1 & m_2 \\ m_2 & m_3 \end{pmatrix}
\]

\textbf{Step 2: Cholesky factorization} $\mat{H} = \mat{L}\mat{L}\T$

\textbf{Step 3: Jacobi matrix} $\mat{J} = \mat{L}^{-1}\mat{H}^{(1)}\mat{L}^{-\top}$

\textbf{Step 4: Eigendecomposition} $\mat{J}\mat{V} = \mat{V}\mathbf{\Lambda}$ gives nodes $x_i$

\textbf{Step 5: Weights} $W_i = m_0 (V_{0i})^2$
\end{keyInsight}

\textbf{Expected Results for $T = 1.0$:}
\begin{itemize}
    \item Nodes: $x_1 \approx 0.0960$, $x_2 \approx 0.6969$
    \item Weights: $W_1 \approx 0.4063$, $W_2 \approx 1.0873$
    \item Moment errors for $n = 0, 1, 2, 3$: all $< 10^{-14}$
    \item Error for $n = 4$: $\sim 10^{-3}$ (beyond exactness guarantee)
\end{itemize}

\textbf{Range Testing:}
\begin{center}
\begin{tabular}{lccc}
\toprule
$T$ & Max Error ($n \le 3$) & Error at $n = 4$ & Notes \\
\midrule
$10^{-8}$ & $< 10^{-14}$ & $\sim 10^{-4}$ & Series expansion needed \\
$10^{-2}$ & $< 10^{-14}$ & $\sim 10^{-3}$ & Stable region \\
$10^{0}$ & $< 10^{-14}$ & $\sim 10^{-3}$ & Stable region \\
$10^{2}$ & $< 10^{-12}$ & $\sim 10^{-2}$ & Nodes cluster near $x = 0$ \\
\bottomrule
\end{tabular}
\end{center}

%-------------------------------------------------------------------------------
\subsection{Exercise 5.3: $(ss|ss)$ by Three Routes [Core]}

\begin{keyInsight}[Three Computational Routes]
\textbf{Setup:} \ce{H2} with $R = 1.4$ Bohr, exponents $\alpha = \beta = \gamma = \delta = 0.5$ (or as specified).

\textbf{Route (a): Closed form with erf-based $\Boys{0}$}
\[
(ss|ss) = \frac{2\pi^{5/2}}{pq\sqrt{p+q}} e^{-\mu R_{AB}^2} e^{-\nu R_{CD}^2} \Boys{0}(T)
\]
where $\Boys{0}(T) = \frac{1}{2}\sqrt{\frac{\pi}{T}}\mathrm{erf}(\sqrt{T})$ for $T > 0$.

\textbf{Route (b): Rys quadrature}
\[
\Boys{0}(T) = \frac{1}{2}\sum_{i=1}^{n_r} W_i
\]
With $n_r = 1$: $\Boys{0}(T) = \frac{W_1}{2} = \frac{m_0}{2}$.

\textbf{Route (c): PySCF \texttt{int2e}}

Use \texttt{mol.intor("int2e")} and extract the appropriate element.
\end{keyInsight}

\textbf{Expected Agreement:}
\begin{itemize}
    \item Routes (a), (b), and (c) should agree to $< 10^{-12}$ for normalized primitives
    \item If using unnormalized primitives, multiply by normalization constants:
    \[
    N_s(\alpha) = \left(\frac{2\alpha}{\pi}\right)^{3/4}
    \]
\end{itemize}

\textbf{Sample Values:}
\begin{itemize}
    \item For $\alpha = \beta = 0.5$, atoms at $(0,0,0)$ and $(0,0,1.4)$:
    \item $(aa|bb)_{\text{normalized}} \approx 0.310$ (depends on exact geometry/exponents)
    \item All three routes: difference $< 10^{-14}$
\end{itemize}

\textbf{Discussion Points:}
\begin{itemize}
    \item Small-$T$ regime ($T < 10^{-10}$): erf-based formula may need series expansion
    \item Normalization conventions: PySCF uses normalized contracted GTOs
    \item Rys approach: Reproduces $\Boys{0}$ exactly (within numerical precision)
\end{itemize}

%-------------------------------------------------------------------------------
\subsection{Exercise 5.4: $(p_\xi s|ss)$ and the Appearance of $\Boys{1}$ [Core]}

\begin{keyInsight}[Derivative Identity]
Starting from Eq.~(5.25):
\[
(p_\xi b|cd) = \frac{1}{2\alpha}\frac{\partial}{\partial A_\xi}(ab|cd)
\]

Apply to the $(ss|ss)$ formula, differentiating both the Gaussian prefactor and $\Boys{0}(T)$:

\textbf{Term 1 (from Gaussian prefactor):}
\[
\frac{\partial}{\partial A_\xi}\left(-\mu R_{AB}^2\right) = -2\mu(A_\xi - B_\xi)
\]
Contributes: $-\frac{\beta}{p}(A_\xi - B_\xi)\Boys{0}(T)$

\textbf{Term 2 (from Boys function):}
\[
\frac{d\Boys{0}}{dT} = -\Boys{1}(T), \quad \frac{\partial T}{\partial A_\xi} = 2\rho(P_\xi - Q_\xi)\frac{\alpha}{p}
\]
Contributes: $-\frac{\rho}{p}(P_\xi - Q_\xi)\Boys{1}(T)$

\textbf{Result (Eq.~5.28):}
\[
(p_\xi b|cd) = \frac{2\pi^{5/2}}{pq\sqrt{p+q}} e^{-\mu R_{AB}^2} e^{-\nu R_{CD}^2}
\left[ -\frac{\beta}{p}(A_\xi - B_\xi)\Boys{0}(T) - \frac{\rho}{p}(P_\xi - Q_\xi)\Boys{1}(T) \right]
\]
\end{keyInsight}

\textbf{Validation Cases:}

\begin{enumerate}
    \item \textbf{Symmetry-zero case:} Atoms along $z$-axis, compute $(p_x s|ss)$
    \begin{itemize}
        \item Both $(A_x - B_x) = 0$ and $(P_x - Q_x) = 0$
        \item Result: $(p_x s|ss) = 0$ (within $10^{-14}$)
    \end{itemize}

    \item \textbf{Nonzero case:} Atoms along $z$-axis, compute $(p_z s|ss)$
    \begin{itemize}
        \item $(A_z - B_z) \neq 0$ and $(P_z - Q_z) \neq 0$
        \item Agreement with PySCF to $< 10^{-10}$
    \end{itemize}

    \item \textbf{Sign test:} Swapping $\mathbf{A} \leftrightarrow \mathbf{B}$ and $\alpha \leftrightarrow \beta$
    \begin{itemize}
        \item Changes which center has the $p$-function
        \item Sign of integral should change (or formula should be re-derived for $b = p$)
    \end{itemize}
\end{enumerate}

%-------------------------------------------------------------------------------
\subsection{Exercise 5.5: J/K Build and Energy Component Check [Core]}

\begin{keyInsight}[J and K Matrix Construction]
\textbf{Coulomb matrix:}
\[
J_{\mu\nu} = \sum_{\lambda\sigma} \eri{\mu}{\nu}{\lambda}{\sigma} P_{\lambda\sigma}
\]

\textbf{Exchange matrix:}
\[
K_{\mu\nu} = \sum_{\lambda\sigma} \eri{\mu}{\lambda}{\nu}{\sigma} P_{\lambda\sigma}
\]

\textbf{In NumPy:}
\begin{lstlisting}
J = np.einsum("ijkl,kl->ij", eri, P, optimize=True)
K = np.einsum("ikjl,kl->ij", eri, P, optimize=True)
\end{lstlisting}

\textbf{Energy reconstruction:}
\[
E_{\mathrm{elec}} = \tr{\Pmat\Hcore} + \frac{1}{2}\tr{\Pmat(\Jmat - \frac{1}{2}\Kmat)}
\]
\end{keyInsight}

\textbf{Test System:} \ce{H2O}/STO-3G with geometry O at origin, H at $(\pm 0.7586, 0, 0.5043)$ \AA.

\textbf{Expected Results:}
\begin{itemize}
    \item $\|\Jmat - \Jmat_{\text{PySCF}}\|_F < 10^{-12}$
    \item $\|\Kmat - \Kmat_{\text{PySCF}}\|_F < 10^{-12}$
    \item Energy agreement: $|E_{\text{tot}} - E_{\text{PySCF}}| < 10^{-10}$ Hartree
    \item PySCF reference: $E_{\text{tot}} \approx -74.9459$ Hartree
\end{itemize}

\begin{warningbox}[Common Errors]
\begin{enumerate}
    \item \textbf{Wrong einsum for K:} The exchange has ``crossed'' indices. Using \texttt{"ijkl,jk->il"} is incorrect.
    \item \textbf{Missing factor of 1/2:} The energy has $\frac{1}{2}$ on the two-electron term.
    \item \textbf{Using $\Kmat$ instead of $\frac{1}{2}\Kmat$:} In RHF, the Fock matrix is $\Fmat = \Hcore + \Jmat - \frac{1}{2}\Kmat$.
\end{enumerate}
\end{warningbox}

%-------------------------------------------------------------------------------
\subsection{Exercise 5.6: Schwarz Screening Toy Study [Advanced]}

\begin{keyInsight}[Schwarz Inequality]
The Schwarz bound states:
\[
|\eri{\mu}{\nu}{\lambda}{\sigma}| \le \sqrt{\eri{\mu}{\nu}{\mu}{\nu}} \cdot \sqrt{\eri{\lambda}{\sigma}{\lambda}{\sigma}}
\]

This enables screening: if the bound is below threshold $\tau$, skip the quartet.
\end{keyInsight}

\textbf{Procedure:}
\begin{enumerate}
    \item Compute all diagonal ERIs $(\mu\nu|\mu\nu)$ for shell pairs
    \item For each threshold $\tau \in \{10^{-8}, 10^{-10}, 10^{-12}\}$:
    \begin{itemize}
        \item Count pairs where $\sqrt{(\mu\nu|\mu\nu)} < \tau$
        \item Estimate screened quartets
    \end{itemize}
\end{enumerate}

\textbf{Expected Results:}

\begin{center}
\begin{tabular}{lccc}
\toprule
\textbf{Basis} & $N_{\text{ao}}$ & \textbf{Screening at $10^{-10}$} & \textbf{Notes} \\
\midrule
STO-3G & 7 & $\sim 5\%$ & Compact, minimal screening \\
6-31+G* & 19 & $\sim 25\%$ & Diffuse functions help \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Physical Interpretation:}
\begin{itemize}
    \item Compact basis functions (STO-3G): Large overlaps, few negligible integrals
    \item Diffuse functions (aug-cc-pVXZ, 6-31+G*): Smaller self-overlaps for diffuse-diffuse pairs
    \item Screening effectiveness increases with molecule size and diffuse character
\end{itemize}

%-------------------------------------------------------------------------------
\subsection{Exercise 5.7: Hankel Matrix Conditioning [Advanced]}

\begin{keyInsight}[Conditioning Analysis]
The Hankel matrix $\mat{H}$ with entries $H_{ij} = m_{i+j}$ becomes increasingly ill-conditioned as $n_r$ grows.

\textbf{Condition number:} $\kappa(\mat{H}) = \|\mat{H}\| \cdot \|\mat{H}^{-1}\|$

Use \texttt{np.linalg.cond(H)} for numerical evaluation.
\end{keyInsight}

\textbf{Expected Results at $T = 1.0$:}

\begin{center}
\begin{tabular}{lcc}
\toprule
$n_r$ & $\kappa(\mat{H})$ & Cholesky Status \\
\midrule
1 & 1.0 & Stable \\
2 & $\sim 10^2$ & Stable \\
3 & $\sim 10^4$ & Stable \\
4 & $\sim 10^6$ & Marginally stable \\
5 & $\sim 10^8$ & May show issues \\
6 & $\sim 10^{10}$+ & Often fails \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Dependence on $T$:}
\begin{itemize}
    \item \textbf{Small $T$ ($< 0.1$):} Moments become similar, worse conditioning
    \item \textbf{Large $T$ ($> 10$):} Moments decay rapidly, may help slightly
    \item Conditioning generally worsens for all $T$ as $n_r$ increases
\end{itemize}

\textbf{Implications:}
\begin{itemize}
    \item High angular momentum quartets need many roots (e.g., $(ff|ff)$ needs $n_r = 7$)
    \item Double precision limits practical use of Algorithm~5.1 to $n_r \lesssim 5$--6
    \item Production codes (libcint) use polynomial approximations or extended precision
\end{itemize}

%-------------------------------------------------------------------------------
\subsection{Exercise 5.8: Obara--Saika Recursion [Research/Challenge]}

\begin{keyInsight}[OS Vertical Recurrence]
The Obara--Saika (OS) method builds higher angular momentum integrals recursively:
\[
(a+1_i\, b | c\, d) = (P_i - A_i)(a\, b | c\, d)
+ \frac{1}{2p}\left[ N_i(a)(a-1_i\, b | c\, d) + N_i(b)(a\, b-1_i | c\, d) \right]
\]
plus ket-side terms.

\textbf{For $(ps|ss)$:} Start from $(ss|ss)^{(m)}$ auxiliary integrals (involving $\Boys{m}$), then apply the recurrence.
\end{keyInsight}

\textbf{Implementation Steps:}
\begin{enumerate}
    \item Research the OS formulas (Obara \& Saika, JCP 84, 3963, 1986)
    \item Implement auxiliary integrals $(ss|ss)^{(m)} \propto \Boys{m}(T)$
    \item Apply vertical recurrence to get $(ps|ss)$
    \item Compare with derivative-based formula
\end{enumerate}

\textbf{Validation:}
\begin{itemize}
    \item OS-based $(p_z s|ss)$ should match derivative-based result to $< 10^{-12}$
    \item Both require $\Boys{0}$ and $\Boys{1}$
    \item Computational structure differs: OS builds up from lower angular momentum
\end{itemize}

\textbf{Comparison: Rys vs OS}
\begin{center}
\begin{tabular}{lcc}
\toprule
\textbf{Aspect} & \textbf{Rys Quadrature} & \textbf{Obara--Saika} \\
\midrule
Approach & Quadrature for Boys & Recurrence relations \\
Auxiliary quantities & Nodes, weights & Auxiliary integrals $(\cdot|\cdot)^{(m)}$ \\
Numerical stability & Issues at high $n_r$ & Generally stable \\
Efficiency & Good for mixed $\ell$ & Good for high $\ell$ \\
\bottomrule
\end{tabular}
\end{center}

\begin{warningbox}[Research Note]
This exercise is open-ended and intended for students interested in exploring alternative integral algorithms. The OS method is widely used in modern quantum chemistry codes (e.g., Gaussian, Q-Chem) alongside Rys quadrature. Understanding both approaches provides insight into the design choices in integral libraries.
\end{warningbox}

\end{document}
